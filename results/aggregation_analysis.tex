% Hierarchical Aggregation Analysis
% CENG543 - Long Document Summarization

\section{Aggregation Strategy Comparison}

We compared two aggregation strategies for sliding window summarization:
\begin{itemize}
    \item \textbf{Concat}: Direct concatenation of window summaries
    \item \textbf{Hierarchical}: Summarizing the concatenated summaries (two-stage)
\end{itemize}

\subsection{Experimental Results}

\begin{table}[h]
\centering
\caption{ROUGE-L Comparison: Concat vs Hierarchical Aggregation}
\label{tab:aggregation_results}
\begin{tabular}{lcccc}
\toprule
\textbf{Experiment} & \textbf{Concat} & \textbf{Hierarchical} & \textbf{$\Delta$} & \textbf{Change (\%)} \\
\midrule
LED\_arxiv\_extra\_long & 0.0489 & 0.0520 & +0.0031 & +6.3\% \\
LED\_longform\_long & 0.0716 & 0.0979 & +0.0264 & +36.8\% \\
BigBird\_arxiv\_extra\_long & 0.0398 & \textbf{0.2073} & +0.1674 & \textbf{+420.2\%} \\
BigBird\_longform\_long & 0.0693 & \textbf{0.2343} & +0.1649 & \textbf{+237.8\%} \\
LED\_arxiv\_long\_w2048 & 0.1185 & 0.1344 & +0.0159 & +13.5\% \\
LED\_longform\_extra\_long & 0.0474 & 0.0618 & +0.0144 & +30.3\% \\
\midrule
\textbf{Average} & 0.0659 & 0.1313 & \textbf{+0.0653} & \textbf{+124.2\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{BERTScore F1 Comparison}
\label{tab:bertscore_results}
\begin{tabular}{lccc}
\toprule
\textbf{Experiment} & \textbf{Concat} & \textbf{Hierarchical} & \textbf{$\Delta$} \\
\midrule
LED\_arxiv\_extra\_long & 0.8192 & 0.7483 & -0.0709 \\
LED\_longform\_long & 0.8169 & 0.7732 & -0.0437 \\
BigBird\_arxiv\_extra\_long & 0.8381 & 0.8400 & \textbf{+0.0019} \\
BigBird\_longform\_long & 0.8387 & 0.8462 & \textbf{+0.0075} \\
LED\_arxiv\_long\_w2048 & 0.8035 & 0.7970 & -0.0065 \\
LED\_longform\_extra\_long & 0.8076 & 0.7470 & -0.0606 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Key Findings}

\begin{enumerate}
    \item \textbf{All 6 experiments showed ROUGE-L improvement} with hierarchical aggregation
    \item \textbf{BigBird models benefited most significantly} (+420\% and +238\% improvements)
    \item \textbf{LED models showed BERTScore degradation} while BigBird maintained or improved BERTScore
\end{enumerate}

\subsection{Possible Reasons for Improvement}

\subsubsection{Why Hierarchical Aggregation Improves ROUGE-L}

\begin{enumerate}
    \item \textbf{Redundancy Elimination}: 
    When window summaries are directly concatenated, overlapping information from adjacent windows creates redundancy. The hierarchical step eliminates these repetitions, producing outputs closer to human-written reference summaries which are typically concise.
    
    \item \textbf{Length Normalization}: 
    Concatenated summaries tend to be significantly longer than reference summaries. ROUGE-L penalizes length mismatches. Hierarchical summarization naturally shortens the output, improving recall-precision balance.
    
    \item \textbf{Coherence and Flow}: 
    Direct concatenation produces disjointed text with abrupt topic transitions. The second-stage summarization creates a more coherent narrative that better matches the reference structure.
    
    \item \textbf{Information Synthesis}: 
    The hierarchical approach allows the model to synthesize key points across all windows rather than preserving window-local details, aligning better with abstractive reference summaries.
\end{enumerate}

\subsubsection{Why BigBird Shows Greater Improvement}

\begin{enumerate}
    \item \textbf{Block-Sparse Attention}: 
    BigBird's block-sparse attention mechanism is more effective at capturing global document structure during the second-stage summarization compared to LED's sliding window attention.
    
    \item \textbf{Model Architecture}: 
    BigBird-Pegasus was pre-trained specifically on summarization tasks (arXiv, PubMed), making it better suited for the hierarchical summarization task.
    
    \item \textbf{Context Utilization}: 
    BigBird's 4K token limit forces more aggressive compression in the first stage, but the hierarchical step allows recovery of coherent summaries from these compressed representations.
\end{enumerate}

\subsubsection{Why LED Shows BERTScore Degradation}

\begin{enumerate}
    \item \textbf{Over-Compression}: 
    The two-stage compression may cause LED to lose semantic details that contribute to BERTScore.
    
    \item \textbf{Attention Mechanism}: 
    LED's local+global attention pattern may be less effective when processing already-summarized text compared to original document content.
    
    \item \textbf{Length-Quality Trade-off}: 
    Shorter hierarchical outputs improve ROUGE-L precision but may sacrifice semantic coverage measured by BERTScore.
\end{enumerate}

\subsection{Conclusion}

Hierarchical aggregation significantly improves ROUGE-L scores (+124\% average) compared to simple concatenation. The improvement is particularly pronounced for BigBird models (+300\% average), which also maintain BERTScore quality. This suggests that:

\begin{itemize}
    \item For ROUGE-L optimization: Use hierarchical aggregation with BigBird
    \item For semantic preservation: Use concat aggregation with LED
    \item The choice depends on evaluation priorities and downstream applications
\end{itemize}
