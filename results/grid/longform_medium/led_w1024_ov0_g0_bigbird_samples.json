{
  "config": {
    "model": "google/bigbird-pegasus-large-arxiv",
    "model_family": "BigBird-Pegasus",
    "attention": "default",
    "window_size": 1024,
    "overlap": 0,
    "global_tokens": 0,
    "category": "longform_medium"
  },
  "summary_stats": {
    "total_samples": 60,
    "avg_rougeL": 0.1333943608126119,
    "avg_bertscore": 0.8242736806472143,
    "min_rougeL": 0.05626134301270418,
    "min_bertscore": 0.7729450464248657
  },
  "samples": [
    {
      "sample_id": 0,
      "doc_id": "dev_longform_169",
      "source_preview": "the research on stellar oscillations within the framework of gr goes back to the early studies of chandrasekhar from almost half a century ago @xcite .\nthe field continues to attract great interest , because the investigation of stellar oscillations can reveal the inner structure of dense stars and shed light on the equation of state of superdense matter . in this paper\nwe focus exclusively on radial oscillations , for which the assumption of spherical symmetry holds . while radial oscillations ",
      "source_length": 16608,
      "reference": "we construct stellar models of hadron stars and hybrid stars and calculate the frequencies of their lowest radial mode of vibration . chandrasekhar s equation for radial oscillations is generalized for stars with internal electric fields and earlier versions of that generalization are simplified . for the hybrid stars a gibbs construction is employed . it is found that the softening of the equation of state associated with the presence of deconfined quarks reduces the oscillation frequency . we show that a slight charge inbalance should lead to increased maximum mass , decreased central density and lower oscillation frequencies .",
      "generated": "we study radial oscillations of hybrid stars with a gibbs construction and realistic equations of state for the quark and hadronic phases . we derive the oscillation equation and present first numerical results .<n> in contrast to previous studies , we investigate charged stars , because we show that the presence of a slight charge inbalance may help to reconcile soft equation of state with observations of massive pulsars . furthermore , an enhancement of the oscillation period at given central baryon density is observed . in our analysis<n> we also assume that the net charge is rather small , so that the star is not destroyed by the coulomb force . we consider compact stars with small total charge and apply the formalism of pulsation theory developed by chandrasekhar to the case of radial oscillations .<n> we find that the amplitude of the radial oscillations is proportional to the net charge of the star , i.e. @xmath0 . for charged stars ,<n> the amplitude decreases with increasing charge density . <n> [ firstpage ] stars : oscillations , methods : analytical , hydrodynamics , in general relativity , classical mechanics , gravitation [ [ section ] ] the study of oscillations of compact objects has a long history @xcite , starting with einstein s general relativity ( gr ) . in the early days of gr , einstein derived the equations of motion ( eos ) for stars with spherical symmetry , which are known as schwarzschild - like metrics . by the middle of the century , however , gr was extended to compact objects of arbitrary shape and mass . as a result , the eos for compact objects became much more complete , and by the end of the twentieth century most of the compact - star eos had been reduced to those of we study the pulsation frequencies of hybrid stars with a realistic equation of state and a quark - gluon plasma .<n> we find that the mass - radius diagram can be well described by a single parameter , the bag constant @xmath0 , which is a measure of the degree of confinement of the quark matter . for a fixed value of the bag<n> constant , there is a maximum mass configuration for which the oscillation frequency is zero in the mass radius diagram . <n> stars with exotic matter ( quarks and gluons ) have been studied intensively in recent years @xcite . in particular , hybrid stars ( hss ) , in which a star of a given mass evolves in mass to form a compact object , are of special interest as they can be used as probes of exotic matter , such as quarks , antiquarks , or quark gluons ( qgp ) as well as a probe of our understanding of the strong interaction . the standard approach to study hybrid stars is to solve the relativistic stellar equations of motion and then calculate the frequencies of oscillations . here<n> , we present a new approach to calculate the frequency spectrum of oscillations in hybrid stars we construct models of rotating hybrid stars , in which deconfined quarks are at the center of the star .<n> the presence of the quarks reduces the oscillation frequencies of the fundamental radial mode . at the onset of the phase transition<n> there is a kink in the frequency curve , which is shifted to lower values . <n> [ [ section ] ] recent observations @xcite , indicate that a large fraction of stars with masses above @xmath0 have a baryon content of more than one baryon per unit mass . in order to explain this observation<n> , it is necessary to assume the existence of exotic matter , such as supermassive black holes , or more generally , massive compact objects with a large mass , rotating about their axis . for a compact object ,<n> the gravitational mass is much larger than the baryon density , and the star can be considered to be a hybrid star , consisting of a black hole and a supermassive quark star ( sqm ) . as a result of the strong coulomb repulsion , the star becomes a charged supermassive star ( cs ) with a mass larger than a few hundred solar masses we present a calculation of the @xmath0 mass difference in p+p , cu+cu and au+au collisions at the kinematics of the cern sps and rhic in the framework of the parton cascade model .<n> we show that the difference between the experimental data and the calculated value is of the order of the nuclear saturation scale and can not be attributed to saturation effects . <n> heavy ion collision experiments at rhic and sps ( e.g. cern - sps , fair , fermilab , bnl , jefferson lab ) are aimed at the search for the quark - gluon plasma ( qgp ) phase transition @xcite . in order to investigate the possible formation of a qgp from the collision of heavy ions at relativistic energies , it is necessary to compute the energy loss of the quarks and gluons , i.e. the so - called energy loss function ( elf ) . for a description of the collision between two light quarks ,<n> the standard perturbative qcd approach ( pqcd ) is employed , while for heavier quarks the relativistic mean - field ( rmf )",
      "metrics": {
        "rougeL": 0.09523809523809523,
        "bertscore_f1": 0.8405198454856873,
        "latency": 4.541078805923462
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 1,
      "doc_id": "dev_longform_675",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Insurance Non-Discrimination for \nSurvivors Act''.\n\nSEC. 2. DEFINITIONS.\n\n    In this Act, except as otherwise expressly provided:\n            (1) Course of conduct.--The term ``course of conduct'' \n        means a course of repeatedly maintaining a visual or physical \n        proximity to a person or conveying verbal or written threats, \n        including threats conveyed through electronic communications, \n        or threats implied b",
      "source_length": 17309,
      "reference": "Insurance Non-Discrimination for Survivors Act - Prohibits an insurer from denying or terminating an insurance policy or health benefit plan, restricting or excluding coverage for losses or denying a claim, or adding a premium differential to any policy or health benefit plan on the basis that the insured (or any employee or any person with whom the insured is known to have a relationship or association) is the subject of, or incurs a claim related to, domestic abuse. Prohibits: (1) an insurer from denying or limiting payment to an insured who is the subject of abuse if the claim for payment is a result of the abuse; (2) an insurer or health carrier from terminating health coverage for a subject of abuse because coverage was originally issued in the name of the abuser and the abuser has divorced, separated from, or lost custody of the subject or the abuser's coverage has terminated and the subject does not qualify for an extension of coverage; and (3) any person employed by or contracting with an insurer or health benefit plan to use, disclose, or transfer specified information (including regarding abuse status) without the subject's consent. Requires: (1) insurers to develop and adhere to written policies specifying procedures to be followed to protect the safety and privacy of a subject of abuse; and (2) an insurer that takes an action that adversely affects a subject of abuse to advise that applicant or insured in writing of the specific reasons for the action.",
      "generated": "we consider the following question : under what conditions can an individual be forced to participate in an activity that is inconsistent with his or her health policy ?<n> we show that the answer is : 1 . <n> a ) the definition of an individual is arbitrary , and includes not only an individual s own fitness , but also the fitness of a number of individuals in the organization . '' <n> 2 . a corporation is not compelled to provide services that are inconsistent with its own health and well - being .<n> <n> 3 . an individual who engages in a particular kind of activity is not forced to do so by the corporation . abuse of plan benefits : i.e. , abuse of a plan by an insurer , a third party , an association , or an omission of benefits , includes : ( 1 ) abuse of the status of an insured ; ( 2 ) any information or data contained in a plan which is obtained by a process of compensation ; and ( 3 ) information which is derived from the existence or nonexistence of a valid policy . <n> [ section ] [ thm]corollary we address the question of whether an individual or an entity acting on behalf of an individual who has been adversely affected by the action of an insurer may obtain a permanent injunctive and compensatory damages in a case involving abuse of a property or an individual .<n> we consider the following issues : ( i ) whether an entity with authority to regulate insurance or to transfer information relating to the mailing or address of an insured or to the addresses of insured or prospective insureds , and to act on the basis of this information and without basis resulting in a violation of this provision , including compensatory damages and costs of the individual and/or the insurer , as well as costs of expert witnesses ; ( ii ) the extent to which the insurer has the authority to provide this information ; and ( iii ) how much the individual must pay in compensatory damages .",
      "metrics": {
        "rougeL": 0.20244328097731237,
        "bertscore_f1": 0.8123564720153809,
        "latency": 4.284795522689819
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 2,
      "doc_id": "dev_longform_30",
      "source_preview": "three years after the first identification of the x - ray afterglow from a gamma ray burst ( grb ) ( costa et al . , 1997 ) , the nature of gamma ray bursts progenitors remains uncertain .\nthe most widely discussed theoretical models for grbs consider vastly different scenarios both in terms of the progenitors and environment .\nif the grbs originate from neutron star - neutron star or neutron star - black hole mergers ( narayan , paczynski and piran 1992 ) then , for about a half of all grbs , t",
      "source_length": 17577,
      "reference": "we report the detection ( @xmath0 significance level ) of a strong iron emission line in the x - ray spectrum of the afterglow of grb 000214 ( `` valentine s day burst '' ) observed by bepposax . an emission line feature was observed with a centroid energy of @xmath1 kev which , if interpreted as k@xmath2 emission from hydrogen - like iron , corresponds to a redshift of z=0.47 . the intensity ( ew@xmath3 kev ) and duration ( tens of hours ) of the line give information on the distance , from the burst region , of the emitting material ( @xmath4 cm ) and its mass ( @xmath5 ) . these results are not easily reconciled with the binary merger and hypernova models for gamma ray bursts , because they require large amounts of mass ( about @xmath6 ) , at large distances ( @xmath7 ) , and at newtonian speeds .",
      "generated": "we report on the detection of an iron emission line in the x - ray spectrum of the afterglow of the gamma ray burst grb 000214 (  valentine s day burst '' ) observed with the bepposax satellite .<n> the line , at @xmath0 , has a fwhm of @ xmath1 km s@xmath2 and a rest - frame equivalent width of about 2 kev , making it the strongest emission line detected so far from a gamma - ray burst afterglow . <n> the observed line flux and equivalent width imply a redshift of the line - emitting region of about 3 , i.e. , very close to the location where the grb occurred . if the redshift is correct , the line emission is consistent with that expected from the ejecta of a hypernova ( or supranova ) explosion at a cosmological redshift . at lower redshifts , corresponding to lower luminosities ,<n> the emission line is predicted to be broadened by the intervening medium , and the line flux is larger , implying a larger redshift and a lower line equivalent width . in the case of a supranova explosion<n> , bepposax observations of grb 000214 were performed about 12 hours after the burst onset .<n> we detected an x - ray source , 1sax j1854.4 - 6627 , at a position consistent with the error circle of the wide field camera ( wfc ) on board the _ swift _ satellite , and a position within the ipn error box of @xmath0 . the 210 kev flux of the source decreased by a factor of about two during this time . <n> the spectral analysis yields a power - law photon index of the order of 2.2 and an unabsorbed flux of about 2@xmath1 erg / s in the energy range 0.1 - 10.0 kev , with a spectral break at about 3 kev and an intrinsic ( corrected for absorption ) column density of about @xcite . from the wfc lightcurve , extending for 39 s<n> after the main event , we derive a flux decay of the form : @x.1pm0.1, ] ] where the @ ] parameter is defined as the ratio of the observed flux in the 0.1 - 4.0 kev energy range to the intrinsic ( unabsorbed we present the results of the observations of the afterglow of grb 000214 , performed with the multi - object spectrometer ( mecs ) on the european southern observatory ( eso ) s very large telescope .<n> we detect an emission line at @xmath0 kev , corresponding to the redshift of 0.47 , in the mecs spectrum , and we identify this feature with the k@xmath1 transition of iron . this is the first detection of an iron line in afterglows of grbs 000214 and 970508 , the two most distant grbs ever observed . <n> the discovery of a supernova ( sn ) associated with a gamma - ray burst ( grb ) @xcite is one of the most exciting results in the field of high - energy astrophysics . in particular ,<n> the identification of the sn - associated afterglow emission lines is of great interest because they can be used to put constraints on the properties of the central engine of the burst , as well as on the physics of the grb itself ( see , for example , larsen et al . 1999 ; piro 1999b ; metzger et al<n> . we report on the detection of the iron line in the reburst of grb 000214 . the line luminosity and the duration of the event are consistent with those of the other bursts with detected iron lines ( grb 970508 , grb 021211 , and grb 990510 ) .<n> we show that the line is emitted by material moving at sub - relativistic speeds ( @xmath0 ) with respect to the plane of the sky , which is consistent with an origin in a massive stellar wind ( vietri et al . , 1999 ) or a massive binary merger ( lazzati , ghisellini , mzard & oskooi , 2000 , 2001a , 2002b , 2003b )<n> this model predicts that the burst was not isotropically emitted , implying that the material must be located at large distances from the burster . in the standard model of gamma ray bursts ( grbs ) @xcite ,<n> the prompt emission is due to the release of energy in a relativistic explosion of a compact object ( neutron star or black hole ) at the center of a massive star ( the progenitor ) ( see , e. we report the first detection of cobalt in the interstellar medium ( ism ) of a supernova ( sn ) .<n> the detection , at @xmath0 cm , was made using the beppo - sax satellite . <n> cobalt has been predicted to be formed in the ejecta of core collapse supernovae ( _ e.g. _ sn1998bw , sn1997ab , ssn1998ac ) and to have an abundance compatible with that of nickel . here<n> we report on the detection of this isotope in the ism of the sn 1999em , which is the first sn to have been found to have its origin in a primordial gas cloud , rather than in a sn ejecta wind , as suggested by some previous studies . in sn1999em<n> , the line width was found to be consistent with that expected from nickel , while in the other cases it was too narrow to be compatible with cobalt , and the line was not detected at all . the first ever detection of a cobalt line in the ( interstellar ) medium ( igm ) @xcite , is important not only because of its possible implications for the sn progenitor s mass ",
      "metrics": {
        "rougeL": 0.13008130081300814,
        "bertscore_f1": 0.8458670973777771,
        "latency": 4.330778360366821
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 3,
      "doc_id": "dev_longform_300",
      "source_preview": "next - to - leading order in  ( ) corrections in di - boson production are large at the cern lhc and sizeable at the fermilab tevatron ( see for example @xcite ) .\nrun  i physics analyses ( i.e. , @xcite ) at the tevatron have employed constant @xmath1-factors to approximate corrections . with the increased energy and luminosity of run  ii and the new energy regime that will be probed with the cern lhc , simulations incorporating higher order corrections will be of increased importance .\ndiffere",
      "source_length": 29246,
      "reference": "we present an algorithm for unweighted event generation in the partonic process @xmath0 with leptonic decays at next - to - leading order in . monte carlo programs for processes such as this frequently generate events with negative weights in certain regions of phase space . for simulations of experimental data one would like to have unweighted events only . we demonstrate how the phase space from the matrix elements can be combined to achieve unweighted event generation using a second stage monte carlo integration over a volume of real emissions ( jets ) . observable quantities are kept fixed in the laboratory frame throughout the integration . the algorithm is applicable to a broader class of processes and is cpu intensive .",
      "generated": "we present an algorithm for unweighted event generation in hadronic di - boson production at hadron colliders .<n> the algorithm makes use of the matrix elements from the baur , han , and ohnemus ( bho ) integration package , which is an extension of the phase space slicing method @xcite . in this method , a cylinder of jets defined by a transverse momentum cutoff @xmath0 is used to partition event generation into a subprocess where the real emission has sufficient transverse momentum to be potentially observable ( called 1 jet ) and another subprocess which has sufficiently small transverse momentum such that it is taken as unobservable . there are no divergences in the 1 jet cross - section so these events all have positive weights and un weighted event generation may be accomplished by applying monte carlo hit - and - miss . the approximations break down before the volume can be increased sufficiently to render all event weights positive . here<n> we present the algorithm for the case of the drell - yan process with next - to - leading order in ( ) corrections . we present a monte carlo event generator for hadronic @xmath0 production at the large hadron collider ( lhc ) based on the phase space slicing method .<n> the algorithm generates a large jet volume such that the cancellations between the real emissions and the one - loop graphs are guaranteed , and the observable quantities are kept fixed in the laboratory frame throughout the integration . as a case study<n> , we apply this algorithm to the process . <n> @=11 citexr[#1]#2@fileswauxout citeaciteforciteb:=#2#1 @=12 0.26 cm 0.2 cm 0.26<n> cm -1 cm # 1#2#3#4#1 * # 2 * , # 3 ( # 4 ) .03 cm * carlo ewerz@xmath1 , eric laenen@ xmath2 , + sergey kovalenko@xcite , * stanley l. weinfurter@x<n> * + .3 cm institute for theoretical physics + tufts university + medford , massachusetts 02155 + stanford linear accelerator center + cambridge , ma 02139 , usa + e - mail we present an algorithm for the reconstruction of jets at the large hadron collider ( lhc ) in proton - proton collisions .<n> the algorithm is based on the phase space slicing method , where the kinematics of an event are sampled using a monte carlo event generation algorithm , and the observables ( rapidities , transverse momenta , etc . ) are integrated over a suitably large volume of phase space . in this paper<n> we apply the algorithm to the case of @xmath0 production with leptonic decays , for which we find that the reconstruction can be improved by a factor of 2 - 3 over that of the next - to - minimal supersymmetric standard model ( nmssm ) prediction , provided that the mass of the neutralino is not too close to the tev scale . *<n> pacs : * 13.85.qk , 13.88.+e , 14.70.pw , 12.60.jv neutrino oscillations @xcite have been a topic of intense study in particle physics since the discovery of neutrinos by the fermilab tevatron , as well as in the context of future colliders such as the lhc we present monte carlo simulation results for the determination of the cross - section for @xmath0 pair production at the large hadron collider ( lhc ) .<n> the results are based on the cteq4 m formalism , and include fixed charged lepton ( n+1 ) and neutrino ( n+n ) vector boson configurations . <n> we have performed a detailed study of the phenomenological impact of _ fixed vector bosons _ ( svbs ) at the lhc @xcite . in this paper<n> we focus on two aspects of svbs which have not been discussed previously : ( 1 ) the effect of the choice of observable vector boson configuration on the calculation of cross - sections ; and ( 2 ) on the use of the phase space slicing method to account for the finite phase space volume of observable vectors . here<n> we present results for both of these issues , as well as the dependence of the results on the variable neutrino mass solution , which is important for the case of the n+1 body case . as an example of a variable mass solution<n> , we consider the case where the neutrino mass is taken to be the same as the mass of the we examine the effect of the presence of negative event weights on the production cross - section for jet subprocess @xmath0 at the large hadron collider ( lhc ) .<n> we find that these events are negligible in the total event sample , but that they have a significant effect on the distribution of the transverse momentum of the final lepton and on the rapidity separation between the @x s and the charged lepton . <n> the production of anomalously heavy quarkonium states at the lhc has long been a subject of intense theoretical and experimental investigation @xcite . in recent years<n> it has become clear that there is a need to re - examine the theoretical calculations in light of the new experimental data , in particular the results from the large electron positron ( lep ) collider at cern , which now provide the highest energy at which such exotic states can be produced . the lepton flavor violation ( lfv ) experiment at the lep collider has measured the properties of the leptonic decays of light quarks and leptons , such as the anomalous magnetic moment ( amm ) of the muon , the mass of the bottom quark , and we describe a monte carlo algorithm for the unweighted generation of events in @xmath0 annihilation at the large hadron collider ( lhc ) .<n> the algorithm is generalizable to a broader class of processes . <n> fermilab - pub-01/024-t + * an algorithm for unweighted event generation at the lhc with leptonic decays * + + + _ fermi national accelerator laboratory , batavia , il 60510 - 5001 , usa _ <n> + + the extraction of the mass and width of the lightest higgs boson is of fundamental interest in particle physics and cosmology . in the standard model ,<n> the higgs mass is given by the mass of the bottom quark , which decays into a pair of bottom quarks and a tau lepton @xcite . at lhc energies , the top quark mass<n> is expected to be in the tev range , so that the top - quark decay into two tau leptons is the dominant decay mode for this boson . as a result<n> , it is possible to study the properties of this light higgs with the atlas and cms detectors , as well as we study the effect of a nonminimal coupling on the @xmath0 dependence of the anomalous magnetic moment of the muon .<n> we find that for a value of the coupling which is in agreement with the experimental value , the anomalous electric dipole moment ( adm ) is suppressed by a factor of about two , compared to the value calculated with the standard model ( sm ) coupling constant . in the case of the sm ,<n> the adm is strongly suppressed for a coupling of the order of the electroweak scale , but is enhanced for larger couplings . <n> the measurement of @xcite of the angular distribution of muons produced at the large hadron collider ( lhc ) will provide a crucial test of the standard - model description of the quark and lepton components of the nucleon , and will shed light on the structure of the qcd vacuum . at the same time<n> , it will be important for understanding the mechanism of electroweak baryogenesis , which is believed to be mediated by the exchange of heavy quarks and leptons in the early stages of the process . for the purpose of this study , we have considered a non - minimal coupling , @",
      "metrics": {
        "rougeL": 0.08452830188679245,
        "bertscore_f1": 0.828842282295227,
        "latency": 5.094830513000488
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 4,
      "doc_id": "dev_longform_281",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Thermal Energy Cooling and Heating \nAct of 2009''.\n\nSEC. 2. CREDIT FOR QUALIFIED DISTRIBUTED THERMAL STORAGE PROPERTY \n              INSTALLED IN A PRINCIPAL RESIDENCE.\n\n    (a) In General.--Subsection (a) of section 25D of the Internal \nRevenue Code of 1986 is amended by striking ``and'' at the end of \nparagraph (4), by striking the period at the end of paragraph (5) and \ninserting ``, and'', and by adding at the end the following new ",
      "source_length": 10840,
      "reference": "Thermal Energy Cooling and Heating Act of 2009 - Amends the Internal Revenue Code to allow: (1) a residential energy efficient property tax credit for 30% of expenditures for distributed thermal energy storage property installed in a principal residence; (2) a 30% energy tax credit for investment in qualified distributed thermal storage property prior to 2017; and (3) financing of qualified distributed thermal energy storage property with new clean renewable energy bonds.",
      "generated": "in this paper , we investigate the relation between thermal energy and the amount of heat that can be extracted from a liquid .<n> we show that a liquid can be very efficient at storing heat if it is cooled in such a way that the heat stored in the liquid is proportional to the square of the temperature of the fluid . in this paper , we address the question of whether it is possible to determine the optimal cooling rate for a given system in terms of the maximum temperature that can be reached in the system .<n> we show that the answer is negative . <n> we consider the following question : is it possible for a system to have an optimum cooling rate ? <n> the answer to the first of these questions is : no . in this case<n> , it is not possible for the system to : ( i ) have an optimal temperature for the given system ; and ( ii ) determine the minimum temperature that the system can reach . here ,<n> the optimal temperature is defined as the maximum possible temperature of the system for which there is no _ a priori _ advantage over the system in reaching this maximum temperature . for the case of a two - phase system , where the first phase is a heat reservoir and the second phase is an electrical reservoir , the optimal optimal temperature can be determined by the second law of thermodynamics : @xmath0 left[eta]right. ] ] in the first case , ( ii) , there is an optimum temperature for",
      "metrics": {
        "rougeL": 0.09404388714733543,
        "bertscore_f1": 0.7840051651000977,
        "latency": 3.8280346393585205
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 5,
      "doc_id": "dev_longform_255",
      "source_preview": "SECTION 1. SHORT TITLE; REFERENCES IN ACT.\n\n    (a) Short Title.--This Act may be cited as the ``Medicare Rural \nHospital Amendments of 1993''.\n    (b) References in Act.--Except as otherwise specifically provided, \nwhenever in this Act, an amendment is expressed in terms of an \namendment to or repeal of a section or other provision, the reference \nshall be considered to be made to that section or other provision of \nthe Social Security Act.\n\nSEC. 2. ESSENTIAL ACCESS COMMUNITY HOSPITAL (EACH) AM",
      "source_length": 16075,
      "reference": "Medicare Rural Hospital Amendments of 1993 - Amends title XVIII (Medicare) of the Social Security Act to extend and revise programs to assist rural hospitals under Medicare part A (Hospital Insurance). Authorizes appropriations. Amends the Omnibus Budget Reconciliation Act of 1987 to reauthorize and extend the rural transition grant program. Amends the Omnibus Budget Reconciliation Act of 1989 to extend regional referral centers. Revises Medicare-dependent, small rural hospital provisions under Medicare. Requires the Secretary of Health and Human Services to provide rural referral centers and Medicare-dependent, small rural hospitals which have been reclassified as urban the opportunity to decline such reclassification.",
      "generated": "in this paper , we address the question of whether there is a lower bound on the average length of stay at a particular facility for a certain patient .<n> we specifically address the following question : 1... how does the lower bound for the average hospital length for a given patient depend on the duration of stay ? <n> 2... what is the relationship between the length of a hospital stay and the amount of care that the hospital needs to provide ?<n> ..<n> the answer to the first of these questions depends on the definition of  acute care '' . in general ,<n> a hospital is said to provide acute care if it is able to treat at least one patient within a period of at least 72 hours . <n> the definition is as follows : a ) for an individual patient , the total number of hours that the individual needs to spend in order to be admitted to the hospital for treatment of that patient is equal to the total amount of time that the patient has spent in that hospital during that period of time , divided by the number of times the individual has been admitted to that hospital for that purpose . '' <n> b ) in section [ 1 ]  we analyze the impact of a hospital - based care model on the quality of long - term care ( lrc ) in a rural setting .<n> our analysis is based on the following assumptions : 1 . <n> (1 ) the relationship between a hospital and the surrounding community is well - defined , well - understood , and does not depend on any special structure of the health care system , nor on the details of the treatment received by the patient , except that the patient is described by the dsr equation , which is determined by the state of the art in evaluating the performance of the system in terms of the number of people served , the relative sizes of the different components of the community and the geographic location of the hospital , as well as the level of coordination of care between the patient and the system of care . 2 . the patient - centered model , _<n> i.e. _ , a set of rules for the treatment of a patient in a community setting , has been well - established and well - studied . in this paper<n> , we will consider the following question : 1 . what is the role of a community - based long - in this note , we address the following question .<n> what is the definition of a rural hospital ?<n> the definition is as follows : a hospital is called a  rural hospital '' if it is located in michigan , the state of usa , and if its inhabitants have health care provided by the state government for at least one year . in 1994 ,<n> an affirmative answer to this question was given in the affirmative in the case of a physico - chemical hospital , as defined in section 3 of ( 1994 ) . <n> here we give an alternative definition of  a hospital '' in section 4 of ( 1993 ) and an answer to the question :  is there an opportunity for a hospital to qualify for such a reclassification ? ''<n> the answer is : there is no opportunity for any such reclassification to occur in any of the geographical areas of the united states . in this paper we show that the state of the art in the field of nuclear and particle physics can be understood in the framework of the theory of superconductivity and superfluidity .<n> in particular , we show the existence of a new class of superconductors , the so - called superconductor - insulator - superconductor ( siss ) class , which is characterized by the following properties : ( i ) the superconducting gap is finite , ( ii ) it extends over a very large range of temperatures , and ( iii ) its structure is that of a superconductor , but not a normal insulator . <n> the superconductor is a state of matter , consisting of electrons , holes and a superconducting condensate . in quantum mechanics ,<n> the superconducting condensate is a phase of matter that is incompressible , with a finite zero - point energy , @xmath0 . at the same time , in nuclear physics , there are two types of superconducting materials , called cooper pairs and normal insulators , where the cooper pairs are superconducting , while the normal insulators are normal , superconducting and anti - superconducting . for a long time<n> , it has been",
      "metrics": {
        "rougeL": 0.07398273736128237,
        "bertscore_f1": 0.7729450464248657,
        "latency": 4.566082954406738
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 6,
      "doc_id": "dev_longform_639",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Incentivize Growth Now In Tomorrow's \nEntrepreneurs Act of 2017''.\n\nSEC. 2. SMALL BUSINESS START-UP SAVINGS ACCOUNTS.\n\n    (a) In General.--Subchapter F of chapter 1 of the Internal Revenue \nCode of 1986 is amended by adding at the end the following new part:\n\n          ``PART IX--SMALL BUSINESS START-UP SAVINGS ACCOUNTS\n\n``Sec. 530A. Small Business Start-Up Savings Accounts.\n\n``SEC. 530A. SMALL BUSINESS START-UP SAVINGS ACCOUNTS.\n\n    ",
      "source_length": 17532,
      "reference": "Incentivize Growth Now In Tomorrow's Entrepreneurs Act of 2017 This bill amends the Internal Revenue Code to create tax-exempt small business start-up savings accounts to pay for the start-up expenses of a business that does not employ more than 50 full-time employees during a taxable year. Cash contributions to such accounts are allowed up to the lesser of $10,000 or the amount of compensation includible in the taxpayer's gross income for the taxable year. (Start-up expenditures are paid or incurred in connection with: (1) investigating the creation or acquisition of an active trade or business; (2) creating an active trade or business; or (3) any activity engaged in for profit and for the production of income before the day on which the active trade or business begins, in anticipation of the activity becoming an active trade or business.)",
      "generated": "we show that the definition of a contribution to a local nonlocal business association is ambiguous . we consider the question of whether a single asset value can be estimated by a simple , straightforward , and straightforward approach , or whether a more sophisticated approach is required .<n> we show that such a characterization is appropriate in the case of a single person with multiple assets , for example , a small business . <n> [ section ] [ thm]proposition [ _ section _ ] the purpose of this paper is to provide a definition of  excess value ' in a simple way that is applicable to a wide range of situations , including situations where the value of an asset is estimated by simple methods , such as the simple method of estimating a value based on a simple formula . in this paper<n> , we will define a  gross value ' for an asset in terms of its value at the time of death , the time at which the value was estimated , as well as the time on which the estimate was calculated . to illustrate the general principles of this definition ,<n> we provide definitions for the values of a number of quantities that are useful in determining the gross value and the amount of excess value in a particular case . as a result of the definition of gross value  the following anomaly has been discovered in the accounts reported in @xcite : 1 . <n> (i ) the individual for whom the account is defined , is maintained with respect to contributions (and the years' after contributions ) , aggregating or more in any calendar year , such as they relate to other matters as they may be , including reports on such matters as to begin with ( @xmath0 ) and to end with  , [e]$ ] , where the amount of this account is determined by the author s annualperkinsperkinsperkins@maine.edu or @xmath1 ] where the author is the director of treasury for the state of michigan , and the author has been with the department of taxation for more than 20 years . for the year 2000 , the author made an error in calculating the contribution to the university of montral of approximately $ 300 , which is in excess of the error reported in the above mentioned error .<n> 2 . in the account of contributions ( and the years ) made for the author after the error is reported , it is necessary to add the following amendment to the account : ",
      "metrics": {
        "rougeL": 0.1378026070763501,
        "bertscore_f1": 0.7828960418701172,
        "latency": 4.0874059200286865
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 7,
      "doc_id": "dev_longform_194",
      "source_preview": "the onset of irreversibility in physics is one of the great questions at the heart of statistical mechanics .\nthe second principle of thermodynamics in essence states that spontaneous processes happen in one direction , namely increasing entropy or decreasing free energy .\nboltzmann s h - theorem was aimed in proving this possibility starting from microscopic time - reversal mechanics , but , as he tragically had to realize , there is no way of doing that . in classical physics irreversibility e",
      "source_length": 28956,
      "reference": "we show that in a quantum system evolving unitarily under a stochastic quantum circuit the notions of irreversibility , universality of computation , and entanglement are closely related . as the state evolves from an initial product state , it gets asymptotically maximally entangled . we define irreversibility as the failure of searching for a disentangling circuit using a metropolis - like algorithm . we show that irreversibility corresponds to wigner - dyson statistics in the level spacing of the entanglement eigenvalues , and that this is obtained from a quantum circuit made from a set of universal gates for quantum computation . if , on the other hand , the system is evolved with a non - universal set of gates , the statistics of the entanglement level spacing deviates from wigner - dyson and the disentangling algorithm succeeds . these results open a new way to characterize irreversibility in quantum systems . _ keywords _ : entanglement entropy , chaos , irreversibility , quantum circuits",
      "generated": "we study the onset of irreversibility in quantum evolution starting from a completely disentangled state . we show that if the evolution is irreversible , the entanglement will be complex in the degrees of freedom in which the interactions are simple . in this sense irreversability is a complexity problem .<n> we posit that entanglement is not neutral ( like energy ) with respect to the degree of freedom that are involved . we show that irreversibility is a property of entanglement , not of how much it is . to this end<n> , we consider discrete quantum mechanical systems made of qubits , and subject to a random unitary quantum circuit .<n> we find that evolution obtained with the full unitary group by means of universal quantum computation is irreversible and the statistics of the level spacings of reduced density matrix spectrum is wigner - dyson , _ i.e _ , is complex . on the other hand , if the entanglement level spacing statistics is poisson , the disentangling algorithm succeeds , which means that the pattern of entanglement is not complex , at least when the evolution is reversible . strikingly , this happens when the set of gates used is not universal for quantum computing . <n> quantum entanglement has been shown to be a useful resource for quantum information processing @xcite . in particular ,<n> the entanglement of a single qubit has been used to construct a universal quantum computer @xmath0 , based on the unitary group of one- and two - qubit controlled - not gates . however , there is a fundamental problem with this approach , namely , how it can be extended to we study the entanglement properties of states that are obtained by evolving with a stochastic quantum circuit .<n> we show that the amount of entanglement present in such states depends on the nature of the quantum circuit and on the number of qubits on which the gates are applied . in particular , we find that the maximal amount of entangledness that can be obtained for a given set of gates is related to the entanglement content of the state under consideration . <n> quantum computing is a powerful tool for simulating quantum many - body systems @xcite . on a classical computer ,<n> the evolution of a quantum state is performed by applying a set of quantum gates , called _<n> gates _ , acting on one or two qubits at a time . as a result<n> , any unitary operation can be expressed as the product of @xmath0 gates : * h * , * p*@xmath1 , and * cnot * . the set of _ gates<n> _ spans the clifford group , which means that any unitary operator can be written in terms of only a handful of types of gates . however , the _ number of operations _ needed to implement any given unitary operation may we show that entanglement cooling is an efficient method to generate maximally entangled states in a stochastic quantum circuit , even if the quantum circuits are not drawn from a universal set .<n> the efficiency of the algorithm is related to the statistics of the level spacing for the entanglement spectrum . <n> entanglement is one of the most intriguing features of quantum mechanics . in the quantum domain ,<n> it has been shown to be a useful resource for quantum information processing @xcite , as well as a powerful resource for simulating quantum many - body systems . however , it is well known that entanglement is not an intrinsic property of quantum systems , but rather a result of decoherence . as such , there is a strong motivation to understand the mechanisms by which entanglement is generated in a quantum system , in particular , how it evolves in time , and how it is affected by the presence of noise in the circuit . here<n> , we study the evolution of an entangled state of @xmath0 qubits , starting from an initial state with maximal entanglement , such as a superposition of eigenstates of the heisenberg hamiltonian . after applying a quantum circuit to this initial state , the system evolves we show that entanglement is not able to distinguish between non - universal sets of gates , as required by quantum theory , and that it is only able to tell apart universal sets in the thermodynamic limit .<n> we use a stochastic quantum circuit to simulate entanglement heating , a process in which a random bit string is heated by applying a set of gates that increase the entanglement of the string . at the end of the simulation ,<n> the entanglement reaches its maximum possible value . <n> entanglement is one of the most important characteristics of quantum mechanics @xcite . for a system of @xmath0 qubits<n> , it has been shown that entanglement can tell apart different sets of quantum gates with good accuracy , _<n> e.g. _ , the cnot gate , which is also the singlet - singlet gate used in the famous heisenberg s uncertainty principle . however , in the presence of disorder , entanglement is expected to decay exponentially with the system size , much faster than it does for a classical system . as a result , quantum mechanics is no longer able to fully predict the behavior of a system at the limit of infinite size . in particular , there is a we propose a cooling algorithm for bipartite entangled states that does not require any computation to be performed on the state . after heating up the system , and before we attempt to cool it , we therefore look at its entanglement spectrum . we find that for all 100 samples tested , the disentangling algorithm is not only unable to bring the state back to a direct product form , but not even to disentangle the state partially .<n> if we observe level repulsion , _ i.e. _ , a wigner - dyson level spacing behavior , then we predict that the system will not be reversed by the cooling algorithm . in theory , entanglement is a useful resource for quantum information processing . however , in practice , it is very difficult to measure the amount of entanglement in a state , because of the enormous variations in the level density . here ,<n> we present a statistical analysis of the entanglement spectrum of an entangled state produced by heating up a binary mixed state and then cooling it to obtain the reduced density matrix . <n> we show that the algorithm is able to return the state to its original form only if the level spacing distribution follows a poisson curve , which is the universal we show that irreversibility and chaotic behavior in quantum mechanics corresponds to a complex pattern of entanglement that can not be undone by entanglement cooling . this pattern is revealed by wigner - dyson statistics in the entanglement level spacing statistics .<n> we speculate that signatures of this behavior may be found in higher moments of the entanglement entropy , since after all , knowledge of all the rnyi entropy should in principle allow to reconstruct the whole reduced density matrix spectrum . <n> quantum mechanics is one of the most studied areas of research in modern physics . despite the fact that quantum mechanics has been around for more than two hundred years ,<n> there is still no consensus on the most appropriate definition of the concept of  quantum ' , let alone on what constitutes a quantum state . in this paper<n> we propose a new way to characterize , through entanglement , quantum systems that do not thermalize , as breaking of thermalization must come from breaking of ergodicity . to this end , we study entanglement evolutions , i.e. , time evolutions of the density matrix of a given quantum state @xmath0 , and show that the statistics of level spacings in this case follow the gue prediction @x",
      "metrics": {
        "rougeL": 0.10625909752547308,
        "bertscore_f1": 0.841803252696991,
        "latency": 4.974263906478882
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 8,
      "doc_id": "dev_longform_711",
      "source_preview": "mechanical stimulation by toothbrushing is capable of inducing keratinization of the \n oral sulcular epithelium , enhance \n gingival circulation , cause \n formation of procollagen synthesis of gingival fibroblasts , and increase alveolar \n bone . \n in addition , it has been \n shown that proliferation of basal cells , fibroblasts and synthesis of procollagen i are \n promoted more effectively by mechanical stimulation with a toothbrush than by removal of \n dental plaque . \n conversely , a very int",
      "source_length": 26184,
      "reference": "periodontitis comprises a group of multifactorial diseases in which periodontopathogens accumulate in dental plaque and trigger host chronic inflammatory and immune responses against periodontal structures , which are determinant to the disease outcome . although unusual cases of non - inflammatory destructive periodontal disease ( nidpd ) are described , their pathogenesis remains unknown . a unique nidpd case was investigated by clinical , microbiological , immunological and genetic tools . the patient , a non - smoking dental surgeon with excessive oral hygiene practice , presented a generalized bone resorption and tooth mobility , but not gingival inflammation or occlusion problems . no hematological , immunological or endocrine alterations were found . no periodontopathogens ( a. actinomycetemcomitans , p. gingivalis , f. nucleatum and t. denticola ) or viruses ( hcmv , ebv-1 and hsv-1 ) were detected , along with levels of il-1 and tnf- in gcf compatible with healthy tissues . conversely alp , acp and rankl gcf levels were similar to diseased periodontal sites . genetic investigation demonstrated that the patient carried some snps , as well hla - dr4 ( * 0404 ) and hla - b27 alleles , considered risk factors for bone loss . then , a less vigorous and diminished frequency of toothbrushing was recommended to the patient , resulting in the arrest of alveolar bone loss , associated with the return of alp , acp and rankl in gcf to normality levels . in conclusion , the unusual case presented here is compatible with the previous description of nidpd , and the results that a possible combination of excessive force and frequency of mechanical stimulation with a potentially bone loss prone genotype could result in the alveolar bone loss seen in nidpd .",
      "generated": "in this paper , we report a unique case study of a non - inflammatory destructive disease ( nidpd ) in which mechanical stimulation resulted from daily oral hygiene was supposed to trigger alveolar bone loss .<n> however , in cases where probing penetration was not prominent and no apparent plaque formation or accumulation of gross calculus were observed , the patient presented no evident radiographic signs of the disease . we present a systematic study of immune - mediated movements of bacteria and viruses in an inflammatory bowel disease patient .<n> specifically , we investigated whether local modifications of the rnarna expression in the patient s colon resulted in changes in the inflammatory state of the system , and whether these changes were correlated with movements of non - destructive mediators , such as bacteria , viruses , cytoskeletal proteins , etc . <n> our results show that local modification of rna expression can lead to changes in both the inflammatory and the non - inflammatory state , but that these changes are not correlated with movement - induced alterations of the mediators . *<n> pacs * : 87.10.+e , 87.23.kg , 89.75.da , 64.70.pf _ keywords _ : inflammatory bowel diseases ( ibds ) , immune mediated diseases ( imds)@xcite , altered metabolisms ( amd ) @xmath0department of radiology , michigan state university , east lansing , mi 48824 - 1321 , usa .@xmath1 corresponding author : e - mail : eli.md in this paper we present a case study concerning the genetic , viral , and inflammatory aspects of a chronic inflammatory disease , described to be a generalized osteoarthritis .<n> we initially investigated the overall systemic condition of the patient , in order to verify whether features like hla or genetic s polymorphism for the extensive bone loss were observed , as observed when the oral sites were evaluated . in addition<n> , we also demonstrated that the patient carried the il6 - gc np - polymorphic polymorphic heterozygous , the aamorphic differential polymorphic hla - coding np , tg 592 - ct , for which the present data were also verified . five years of follow - up<n> radiographic investigations showed no evident progression of the clinical condition , including bone loss , when compared to the initial conditions . <n> moreover , after controlling the disease progression in the generalized horizontal alveolar fluid in which an unbalanced host immune response to periodontopathogens is also recognized as infectious diseases , no further evidence of a disease progression was found when compared with the initial findings . here<n> we present the case study of an individual with a generalized arthritis , characterized by the we investigated the genetic and immunological background of a special case of chronic periodontitis , in which the patient presented a satisfactory phenotype and no evidences of inflammatory activity were found at immunological investigation .<n> however , the patient showed an intensive oral hygiene care period and bone lesion , suggesting an elevated bone metabolism in the diseased sites . in this case<n> , we next inspected some single nucleotide polymorphisms ( snp ) that could characterize a susceptibility phenotype . <n> first , all the evaluated sites were compatible with those seen in clinically healthy tissues , and half of the investigated snps suggest the occurrence of risk alleles for bone loss . on the other hand ,<n> the polymorphic heterozygous of the tfb -509tgnp seems to be a greater risk for the development of the disease , as compared to the mmp1 - 1607 genotype , regarding the gc t allele . in this study , the genetic basis for alveolar bone loss ( gcf ) of a patient with mechanical bone resorption was analyzed .<n> the mmp-1 genetic allele was previously associated with severe chronic immunological disorders ( hla - dr4 subtypes 0401 , 0405 and 0408 ) in brazilian patients and mm-1 mrna genotype mm-1 ( including qrraa * 0404 ) , which showed severe resorption of bone cells , in addition , it was previously demonstrated to be associated with a non - infectious and non - inflammatory disease progression in the clinical literature . <n> [ [ section ] ] in this paper , we present the results obtained from the analysis of the genetic properties of gcf of a brazilian patient with severe mechanical bone loss . in particular ,<n> we focus on the genetic origin of the patient s gcf and analyze the expression of the nidpd allele in the context of the development of hla dra / b heterodimer ( _ hla_-drb1 ) associated _ with _ severe _ and _ chronic _ periodontitis . the hla analysis showed that the patient carried the _<n> in this paper , we present a new method for the diagnosis of gum disease , based on the _ in situ _ characterization of the gum tissue in the patient .<n> we show that , in some cases , the characterization can be improved by the use of a digital image . <n> _ keywords : _ gum disease ( gd ) , nidpd , scaling and receding , 3dph . the gd is the first stage in the irreversible process of irreversible irreversible transformation of the tissues of the mouth and teeth , which , under the action of forces , lead to the irreversible irreversible loss of the teeth and gum tissue , and , eventually , to the breakdown of the body s immune system . in the framework of the general theory of irreversible processes of irreversible transformation ,<n> gd was first described in @xcite and its basic features were then experimentally investigated in the case of @xmath0 gum disease in a human being . since then , it has been experimentally confirmed in a large number of human beings , both living and dead , by a variety of different methods , such as _<n> in vitro _",
      "metrics": {
        "rougeL": 0.13000890471950136,
        "bertscore_f1": 0.8213233351707458,
        "latency": 4.806085824966431
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 9,
      "doc_id": "dev_longform_403",
      "source_preview": "eclipsing binary star systems ( ebs ) are our primary source of measurements of the properties of stars @xcite .\nthey are vital tracers of the physical processes which govern stellar structure and evolution @xcite . from time - series photometry and spectroscopy of an eb it is possible to measure the masses and radii of the two stars empirically , and to accuracies of better than 1% ( e.g. * ? ? ?\n* ; * ? ? ?\nthese numbers in turn give the surface gravity and mean density of the stars .\nif measu",
      "source_length": 18519,
      "reference": "we present _ kepler _ satellite photometry of kic10661783 , a short - period binary star system which shows total eclipses and multi - periodic @xmath0scuti pulsations . a frequency analysis of the eclipse - subtracted light curve reveals at least 68 frequencies of which 55 or more can be attributed to pulsation modes . the main limitation on this analysis is the frequency resolution within the 27-day short - cadence light curve . most of the variability signal lies in the frequency range 18 to 31 d@xmath1 , with amplitudes between 0.1 and 4 mmag . one harmonic term ( @xmath2 ) and a few combination frequencies ( @xmath3 ) have been detected . from a plot of the residuals versus orbital phase we assign the pulsations to the primary star in the system . the pulsations were removed from the short - cadence data and the light curve was modelled using the wilson - devinney code . we are unable to get a perfect fit due to the residual effects of pulsations and also to the treatment of reflection and reprocessing in the light curve model . a model where the secondary star fills its roche lobe is favoured , which means that kic10661783 can be classified as an oea system . further photometric and spectroscopic observations will allow the masses and radii of the two stars to be measured to high precision and hundreds of @xmath0scuti pulsation frequencies to be resolved . this could lead to unique constraints on theoretical models of @xmath0scuti stars , if the evolutionary history of kic10661783 can be accounted for . stars : binaries : eclipsing stars : fundamental parameters stars : oscillations stars : variables : delta scuti",
      "generated": "we present the analysis of _ kepler _ short - cadence and long - cadence photometry of the @xmath0scuti star kic10661783 , a detached eclipsing binary system .<n> the components of this system are shown to be a double - lined eclipsing binary with an orbital period of 30.5h and an eccentricity of 0.125 . using the 2mass magnitudes of the system and the infrared flux method , we measure the effective temperatures of the two stars to be t@xmath1k and t=7k , respectively , and the radii of the components to be 8.71 and 7.80@xcite . the high photometric precision and the high duty cycle of the data allow us to perform a detailed analysis of the pulsations , which reveal the presence of a large number of modes with frequencies ranging from 0.1 to 100hz , including several mixed modes and high - order mixed modes . we have also identified the fundamental stellar parameters of the stars empirically and to accuracies of better than 1% using the asteroseismology technique . <n> [ firstpage ] stars : oscillations binaries : eclipsing techniques : photometric we present _ kepler _ observations of the eclipsing binary kic10661783 , a double - lined spectroscopic binary with a period of @xmath0d .<n> the secondary star is found to be variable on the timescale of hours , with a semiamplitude of about 5hz , and a period similar to that of the primary star , which is also variable on timescales from hours to years . <n> we have used the wilson - devinney stellar model code to fit the light curve of the system , including the light contribution of the two stars , together with the orbital period and the radial velocity of the secondary , to obtain the physical parameters of the stars : ( 1 ) the secondary is a massive main - sequence star with a mass of m@xmath1 ; ( 2 ) it is a low - mass semidetached binary ; and ( 3 ) its light curve is dominated by pulsations from a pulsating primary star with an amplitude of about 3hz . in the case of kic 10661783<n> , we find that the system is a semi - detached binary , in the sense that the mass ratio between the two components is @x we present _ kepler _ photometry of kic10661783 , a semi - detached eclipsing binary system which shows total eclipses and multi - periodic @xmath0scuti pulsations .<n> the data were augmented with superwasp observations in order to precisely measure the orbital period of the system . we report the discovery of kic10661783 , a semi - detached oea ( oscillating algol ) star , using data from the _ kepler _ satellite .<n> this star is a high - amplitude @xmath0scuti pulsator with an orbital period of 15.9 d and a semimajor axis of 0.08 r@xmath1 . <n> [ firstpage ] stars : oscillations techniques : photometric binaries : spectroscopic radial and nonradial pulsations from young stellar objects ( ysos ) are important probes of their internal structure and evolution . here<n> we present the results of a search for radial oscillations ( rr ) from young , low - mass stars ( @xmath0 1 m@xmath1 ) using the multi - object spectrograph ( mos ) on the 6.5 m keck ii telescope .<n> our survey is designed to detect rr in the range from 10 to 100 hz , and to measure the amplitude of the oscillations to an accuracy of a few percent . using the mos<n> , we obtained a radial velocity variation ( rv ) signal with a mean precision of 12 m s@xcite , which we use to determine the rotational period of the host star to be 3.39 days , a value consistent with the periodicity of the rotational modulation . <n> stars are believed to be born with a broad range of radii , from a few tens of au to a few hundreds of au , at the bottom of their convective zones . in low mass stars ,<n> the radius is much less than the hydrogen - burning limit , so , the",
      "metrics": {
        "rougeL": 0.1698754246885617,
        "bertscore_f1": 0.8554238080978394,
        "latency": 4.619613885879517
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 21,
      "doc_id": "dev_longform_236",
      "source_preview": "in 1936 , alan m. turing gave an example of a well - founded ( and thus mathematically solvable ) problem which he showed to admit no computable solution .\nmore precisely he first introduced what is now called the turing machine ( ) as an idealization ( ` _ _ model _ _ ' ) of a digital computer and revealed it capable of solving a vast variety of practical problems like , for instance , answering whether a given integer is prime .\n[ defproblem ] a computational _ problem _ is a subset @xmath0 .\n",
      "source_length": 29335,
      "reference": "recent works have independently suggested that quantum mechanics might permit for procedures that transcend the power of turing machines as well as of ` standard ' quantum computers . these approaches rely on and indicate that quantum mechanics seems to support some infinite variant of classical parallel computing . we compare this new one with other attempts towards hypercomputation by separating 1 ) its principal computing capabilities from 2 ) realizability issues . the first are shown to coincide with recursive enumerability ; the second are considered in analogy to ` existence ' in mathematical logic . * keywords * : hypercomputation , quantum mechanics , recursion theory , infinite parallelism . + * pacs * ( 2003 ) : 03.67",
      "generated": "the well - known turing machine ( ) is a digital computer capable of solving a vast variety of practical problems like , for instance , answering whether a given integer is prime .<n> it was first introduced by alan m. turing in 1936 as an idealization (  _ _ model _ ' ) of a digitalcomputer and revealed its ability to decide within finite time whether @xmath0 does _ not _ halt . since then , many further sensible notions of computability have been proposed , among them herbrand - gdel - computable , fermat s tenth problem , turing s halting problem and others . in this paper<n> , we give an example of a well - founded ( and thus mathematically solvable ) problem which can not be decided algorithmically . <n> * keywords : * halting problem ; turing machines ; recursion theory ; quantum computers . *<n> 2010 mathematics subject classification :* 90c27 , 90c26 , 68w30 . [ section ] [ theorem]corollary [ theorem ] proposition [ theorem],lemma [ theorem][ theorem]proposition [ lemma] we consider the fundamental computing capabilities of a _<n> hypercomputer _ , i.e. , a machine that can not solve either of the following two problems : 1 . ) _ any _ halting problem ; 2 .<n> _ a finite control ( the  program ' , so to speak ) and a finite amount of information each ( e.g. : a bit or an integer ) stored in a memory cell ; 3 . a initially blank , countable supply of memory cells . we show that , in contrast to post s problem , there exists an entire hierarchy of undecidable problems strictly  easier ' than @xmath0 . more precisely they constructed problems @xcite that a can__not _ decide , yet access to whose solution ( in terms of an oracle , that is , by permitting queries to some hypothetical external device answering questions _ super_- )<n> provably still does not enable this _super_- to solve the halting problem. <n> * keywords : * _ hypercomputation , hypercomputers , turing machine , halting problem * ams we lift condition d , that is the principal computing power of infinite parallelism .<n> we show that condition d is equivalent to condition c in the theory of turing s tenth problem and thus provides a new approach to the existence of hypercomputers an approach _ not _ covered by ord s classification . <n> _ keywords : _ quantum computation , hypercomputer , condition d we analyze the capabilities of an _ infinite _ number of parallel machines .<n> in particular , we show that they are provably more powerful than a single one . we show that hilbert s tenth problem and the halting problem can be solved by means of turing - parallelism .<n> more precisely , given a problem @xmath0 and a countably infinite family of s working in parallel , we show ( i ) that , _ if _ each input of any s is input and _ all _ outputs of the family eventually terminate , and ( ii ) : * _ _ given each input , ( a ) if the family of outputs of _ any _ input of  any '' s terminates in finite time and ( b ) the gdel number of the corresponding encoding of the input is bounded independently of the size of the s family . <n> we then show that this _ infinitely parallel computability _<n> ( i - iv ) also yields an interesting non - trivial way of hypercomputation . more precisely we show , in this sense , infinite turing _ parallelism _ can _ solve _ the halting _ problem _ as well as the tenth problem * but _ not_. while @xcite shows that the hilbert tenth problem is solvable we investigate whether the infinite dimensions of quantum mechanical hilbert space allow for _ classical _ ( i.e. , _ infinite _ ) turing - parallelism .<n> more specifically , we show that , if @xmath0 is a _ semi_-decidable problem , that is , a problem iff it is solvable in the sense of definition [ defparallel](i - iv)iff semi - decidable , then there exists an _ idealized _ finite turing parallelism , namely , an infinite number of parallel hilbert s tenth problems simulating each other , for each input , in such a way that output is  1 '' , and iff iff ( i)@xmath1 . in other words , there is a fixed further , which , given an encoding of the hilbert tenth problem into another one , outputs ( i ) as above . this classical parallelism is shown to be sufficient for solving both the halting problem as well as the tenth problem . as a corollary<n> , it follows that the principal computational power of an idealized infinite turing concurrency is the number of outputs , @x in this paper we discuss the limits of computation , in particular the question of existence of algorithms that are turing - computable . <n> turing computability is defined as the limit of computation by turing s theorem @xcite , which states that : @xmath0 there exists an algorithm for computing the product @xmath1 between two given functions . ''<n> the proof of the existence of such an algorithm is based on a theorem of adamyan , calude , pavlov , bennett , landauer , and blass ( * ? ?<n> ? section 7.2 ) .<n> the problem with the definition of the  limit '' of computation is that it is not defined for the finite - dimensional case of  standard ' quantum computing , i.e. for algorithms which are  im - practical '' . in the finite dimensional case<n> only recently has it become possible to read out a single spin @x<n> . however , such algorithms are not im -practical , as they do not exist in the real world . here<n> we show that , contrary to what is stated in the above paper  we consider the problem of computing the non - computable in the context of the theory of hypercomputation .<n> we show that it is possible to formulate a computability principle which is consistent with the turing theorem . <n> [ firstpage ] _ introduction : _ in the last decade , there has been a growing interest in the study of the computables of physical theories . in particular , many papers have been written on the noncommutability of numbers @xcite , enumerability of sets , and the computation of non - trivial constants , to name only a few . here<n> , we will consider the question : what is the notion of a nontrivial constant @xmath0 , that is , the minimum number of operations required to compute the nontrivial value of a function ? <n> the answer to this question is : * it is not a trivial constant . *<n> * it has been observed by many authors that there is an intimate connection between the noncomputableness of a physical theory and its enumerable set theory , for example , this is the case for gdel s _ _ comput",
      "metrics": {
        "rougeL": 0.05626134301270418,
        "bertscore_f1": 0.80640709400177,
        "latency": 5.321125745773315
      },
      "selection_reason": "worst_rouge"
    },
    {
      "sample_id": 20,
      "doc_id": "dev_longform_512",
      "source_preview": "the winds of o and wr stars couple high mass - loss rates of @xmath1 to a few times @xmath2 with fast velocities typically @xmath3 .\nthe ram pressure balance between the hypersonic winds determines the position of the wind - wind collision region ( wcr ) .\nshocks are formed either side of the wcr which thermalize the plasma , heating it to @xmath4k .\nthe properties ( e.g. density ) of the wcr can span a very large range ( see e.g. table  2 in * ? ? ?\n* ) , reflecting the diversity of the underly",
      "source_length": 25009,
      "reference": "the powerful wind - wind collision in massive star binaries creates a region of high temperature plasma and accelerates particles to relativistic energies . i briefly summarize the hydrodynamics of the wind - wind interaction and the observational evidence , including recent @xmath0-ray detections , of non - thermal emission from such systems . i then discuss existing models of the non - thermal emission and their application to date , before concluding with some future prospects .",
      "generated": "the winds of o and wr stars couple high mass - loss rate and hypersonic velocities .<n> the ram pressure balance between the hypersonic winds determines the position of the wind - wind collision region ( wcr ) . shocks are formed either side of the wcr which thermalize the plasma , heating it to @xmath0k . particle acceleration at the shocks<n> is likely to occur in wider systems , particularly since the changing separation of the stars is useful as a probe of the physics which takes place . colliding wind binaries ( cwbs )<n> are also useful as simpler , less complicated , analogues of the multiple wind -wind collisions which occur throughout the volume of clusters of massive stars . here<n> we review the results of hydrodynamical simulations of the collision of the winds in massive stars binaries . in this paper , i review the current status of our understanding of the non - thermal emission from wr+o binaries .<n> i focus on the recent integral and suzaku observations of wr140 , wr146 , and wr147 , which have provided strong evidence for the presence of non -thermal radio emission from these systems , as well as new constraints on the nature of this emission . <n> i also present the results of a new , deep , @xmath0-ray observation of the cwb in wr 147 , with the goal of constraining the properties of the wind of the o star . using this new data , along with previous , lower resolution , observations ,<n> i show that the o - star s wind has a mass loss rate of at least a factor of two lower than previously thought . as a result<n> , the mass - loss rate implied by the new data is much lower than the previously assumed value , implying that the wind momentum ratio of the system is smaller than previously believed . in the case of , however , this result is entirely due to the lower mass of this star , a result which is consistent with we present new models of the radio and @xmath0-ray emission from colliding wind binaries ( cwbs ) .<n> the models are based on hydrodynamical simulations of the wind - wind interaction , and include a full treatment of inverse compton ( ic ) cooling of the non - thermal electrons in the wcr . <n> we find that the total synchrotron emission from the entire wcr in adiabatic systems scales with the inverse - compton parameter , @x , as : ( i ) @xxmath1 , with a characteristic value of the lorentz factor , t@xmath2 , in the range of 10 to 100 ; ( ii ) the ic cooling timescale is proportional to the local magnetic field energy density ; and ( iii ) for a given set of parameters , the radiative efficiency of the thermal wcr is a decreasing function of the distance from the center of the system . as a result of these changes ,<n> the synchrotron flux from the whole wcr scales with t as , e.g. , ( i.e. ) a power - law with an exponential cutoff , we review the models of the x - ray and @xmath0-ray emission from colliding wind binaries , and their implications for the interpretation of observations .<n> in particular , we focus on the ic emission from wr140 , which is expected to be detectable with glast / fermi , as well as on wr20a , a wr+wr binary , for which no firm conclusions can be drawn at present from the available data . <n> [ firstpage ] x - rays : binaries stars : winds , outflows radiation mechanisms : non - thermal . in recent years there has been a steady improvement in theoretical model predictions of the non - thermal emission from cwbs , in both the radio and @xmath0-ray domains .<n> this work is being driven by corresponding advances on the observational front . in this paper ,<n> i review some of the recent work , and discuss some future prospects . we report on the @xmath0-ray emission of a luminous x - ray transient ( lxt ) discovered by _<n> integral _ in the course of a search for relativistic jets in the cosmic microwave background ( cmb ) anisotropy .<n> the transient was found to be a compact source of soft photons with a flux of @xcite , which was identified with the xte source rx j1249.4 - 2843 . <n> the x - rays from this source are characterized by a soft spectrum , with a photon index @x a@xmath1 , and a flux above the extrapolation of the extrapolated value of the unbeamed spectrum . in the framework of the bcs theory<n> , the origin of the soft photons can be attributed to the interaction of the accelerated electrons with the ambient medium , i.e. , to the thermal bremsstrahlung emission of the cmb electrons , or to the decay of the relativistic electrons into free nucleons , as in the case of the galactic cosmic rays ( gcrs ) . since the discovery of the first ultra - high energy cosmic ray ( uhecr ) by becker et we report on the observation of x - ray emission from the binary pulsars psr j0737 + 6736 and psrs j1327 + 6716 , which have a spin - orbit coupling of @xmath0 .<n> x - rays were detected with a high - resolution , high signal - to - noise ratio , optical interferometer at the indiana university cyclotron accelerator , bloomington , in the energy range of 300 - 700 mev , and with a timing resolution of 20 ns . <n> pulsars , as they have been shown to be very efficient accelerators , can produce high - quality data in a very short time . in this letter , we present the results of the analysis of the emission of high - energy gamma - rays from pulsars with spin - orbital coupling ( soc ) , i.e. , when the spin axis of the pulsar is perpendicular to the orbital plane of the companion star , @xcite . the analysis is performed by means of the two - dimensional ( 2d ) time - dependent density - functional theory ( tddft ) in the framework of the non - equilibrium green s function ( neg",
      "metrics": {
        "rougeL": 0.07079646017699115,
        "bertscore_f1": 0.8379150032997131,
        "latency": 4.967368125915527
      },
      "selection_reason": "worst_rouge"
    },
    {
      "sample_id": 10,
      "doc_id": "dev_longform_641",
      "source_preview": "for @xmath0 centre - of - mass ( cm ) collision energies above the @xmath1 pole , @xmath10 , an important contribution to the cross section for @xmath11  jets comes from the so - called `` photonic returns to the @xmath1 '' , i.e events in which one or more photons are emitted by the colliding electron - positron beams prior to the annihilation of the latter into the virtual @xmath1 @xcite .\nsuch emission can carry away a large fraction of the collider energy , so that the amount left over for t",
      "source_length": 28769,
      "reference": "the production of four hadronic jets in @xmath0 collisions above the @xmath1 pole is dominated by the qcd @xmath2 processes and , for sufficiently high energy , the electroweak @xmath3 process . however there is another mechanism for producing four jets , @xmath4 , which can be regarded as a `` hadronic return '' to the @xmath1 pole . we investigate this new process in detail . 0 pt 42by .25 truein .25 truein 1 in 0.75 in 6.35 truein = 100000 # 1 # 2 # 3 _ phys . lett . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ nucl . phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ j. phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ z. phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ phys . rev . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ phys . rep . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ phys . rev . lett . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ mod . phys . lett . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ rev . mod . phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ sov . j. nucl . phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ comp . phys . commun . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 * # 1 * , ( # 2 ) # 3 ral - tr-98 - 036 + dtp/98/14 + june 1999 + * hadronic returns to the @xmath5 + in electron - positron annihilation at high energy * + v.a . khoze@xmath6 , d.j . miller@xmath7 , s. moretti@xmath8 and w.j . stirling@xmath9 + _ a ) department of physics , university of durham , _ + _ south road , durham dh1 3le , uk . _ + _ b ) infn laboratori nazionali di frascati , _ + _ p.o . box 13 , i-00044 frascati ( rome ) , italy . _ + _ c ) rutherford appleton laboratory , _ + _ chilton , didcot , oxon ox11 0qx , uk . _ + _ d ) department of mathematical sciences , university of durham , _ + _ south road , durham dh1 3le , uk . _ +",
      "generated": "hadronic  returns '' to the @xmath0 centre - of - mass collision energy in the vicinity of its peak may constitute a sizeable background at lep2 and/or a future linear collider .<n> such events are characterized by the emission of two energetic gluons in an internal quark - antiquark loop , allowing for a reduction of the collision energy to the order of a few gev / c@xmath2 . <n> cern - ph - th/2007 - 263 + desy 07 - 093 + hep - ph/0701271 + * hadronic returns to the * + + + @xcite + s.j . stirling + _ theory division , cern , ch-1211 geneva 23 , switzerland _ +  sergio.strivisa@cern.ch  _ <n> + t. gehrmann - zerwas + <n> _ department of physics , university of helsinki , p.o . box 64 , fin-00014 , + and + institut fr theoretische physik , johannes gutenberg - we calculate the cross section for the process @xmath0 in the standard model .<n> the dominant background comes from the decay of the @xcite ( hr ) boson to two jets . however , the topology of such events is very different from the hr one . in particular , there is a strong peak in the jet jet mass distribution , which can not be accounted for by the usual one - loop feynman diagrams , and also , if kinematics allow , at a kinematics that is very similar to that of the tevatron collider . as a result ,<n> there is only a small background from the electroweak production of the higgs boson . <n> @=11 caption#1[#2]#3 @=12 .7ex gev mev ev kev tev m_z m_pl _ -1  -1 * d * * d * * * u * * | * u * # 1 # 1#2#3#4#1 * # 2 * , # 3 ( # 4 ) cern - ph - th/2005 - 074 + desy 05 - 065 + ift - uam / csic we study the hadronic returns to the top quark in @xmath0 collisions at lep2 and nlc energies .<n> we find that the production rates are strongly dependent on the gluon mass , and can be enhanced by up to two orders of magnitude when the top mass is increased from its value of 130 gev @xcite . at the same time<n> , the cross sections for the production of the bottom quark are found to be strongly suppressed , in agreement with the results of ref . <n> [ s : gpp ] , where it was shown that the cross section for the bottom - quark production is suppressed by a factor of @xxmath1 compared to its value at the tevatron . in this paper , we present a detailed analysis of the production and decay of the top and bottom quarks at hadron colliders , with special emphasis on the case of the processes @x ,  left(fracsqrt1right)2$ ] and <n> right(phys.rev.q ) 2  $ ] ( or , alternatively we consider the production of higgs bosons in association with a photon in high energy @xmath0 collisions .<n> we show that such events are copiously produced at an nlc running at 500 gev , and that they can be used to test the electroweak standard model . in this context , we also discuss the possibility of observing higgs production via the @xcite mechanism . <n> it has been proposed some time ago that high energy photon - photon collisions could be used as probes of electroweak symmetry breaking in the context of the standard model ( sm ) . at the same time<n> , it is of interest to see if the sm predictions are robust enough to be tested at future colliders , such as the large hadron collider ( lhc ) and the next linear collider , or even the tevatron , which is currently under construction in the u.s . the interest in this subject goes back to the early days of the sm , when it was suggested that the higgs sector could be probed by the electro - weak process , i.e. by the production and subsequent decay of two gluons in the final state , @x we point out that the interference between the tree - level @xmath0 amplitudes and those of the next - to - leading order ( nlo ) qcd diagrams in the production of four - quark pairs in high - energy hadronic collisions could lead to observable effects in the four - jet final state at lep2 and tevatron energies . <n> lpt orsay 08 - 70 + cpht - rr-08 - 005 + hep - ph / yymmnnn + july 8 , 2008 3.5 cm * interference between tree level and nlo qcd amplitudes in high energy hadron production * 1.cm t. gehrmann@xmath1 and w.j . stirling.4 cm _<n> laboratoire de physique thorique et hautes energies + universit de paris xi , centre dorsay , bt .<n> 211 + 91405 orsay cedex , france _ <n> 3.cm * abstract * .3 cm ( 0,0)(0,0 ) ( 340,290)buhep - th-08 - 09 + mpi - pht-08 - 28 + july 15 , 2007 3.5 cm ( we study the effects of what we have called  hadronic returns '' to the @xmath0 boson , in which a primary current originates a quark loop from which two gluons are emitted in association with the latter .<n> these are a novel source of two - lepton two - jet and four - jet events which could , _ a priori _ , constitute a problematic background for studies at lep2 and nlc . we have also calculated the hadronic contributions as a process on its own , by integrating the amplitude squared of the relevant perturbative graphs , as well as the interference of these with the tree - level diagrams for quark - antiquark - two - gluon production . <n> cern - th/2001 - 263 + ific/01 - 30 + ftuv/01 - 13 + hep - ph/0106068 + * hadronic higgs returns to the * + + _ submitted to physics letters b _ + the existence of the higgs boson is one of the most important predictions of the standard model ( sm ) of particle physics . in its present state<n> , it is still unknown whether it is composed of quarks or gluons we calculate the high - energy ( hr ) contributions to the @xmath0 production cross - section in the standard model . in every channel studied , the effects of the hr contributions are completely negligible at lep2 . however , at an nlc with energy between 350 and 500 gev , they can be observed at a rate of a few per 100 inverse femtobarns , whereas their interference with the tree - level contribution to the total four - jet rate is negligible also at the nlc . thus , these contributions are significant enough to merit attention when proceeding to experimental studies of high luminosity data samples . <n> epsf 23.0 cm 17.0 cm -1.0 in -42pt @=11 tempcntc citex[#1]#2@fileswauxout tempcnta@tempcntb@neciteaciteforciteb:=#2citeo#1 citeotempcnta > tempcnt b @=12 <n> @=14 # 1 # 1 = cmssbx10 scaled 2 to we consider the possibility that the @xmath0 meson may have a nonzero vacuum expectation value ( vev ) .<n> if this is the case , it is possible to determine the value of the vevs by solving a coupled set of equations of motion for the meson masses and baryon chemical potentials . <n> the existence of a non - zero vacuum expectation is a necessary and sufficient condition for a meson to be stable . in the simplest version of the standard model ( sm )<n> , there is an upper bound on the masses of the light quarks and leptons that is given by @xcite . on the other hand , in the minimal supersymmetric extension ( mssm ) of the sm ,<n> there are no constraints on the mass of the heavy quarks or leptons , except for the fact that the lightest supersymmetric particle ( lsp ) should be massless . at the tev scale , where the supersymmetry ( susy ) breaking scale is of the order of the weak scale ( wl ) or smaller , the lightest neutral mesons ( lhms ) may have masses as low as @",
      "metrics": {
        "rougeL": 0.0782198246797033,
        "bertscore_f1": 0.8079968690872192,
        "latency": 5.326860666275024
      },
      "selection_reason": "worst_rouge"
    },
    {
      "sample_id": 40,
      "doc_id": "dev_longform_49",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Immigration Law Enforcement Act of \n1993''.\n\n   TITLE I--BORDER PERSONNEL, TRAINING AND INFRASTRUCTURE ENHANCEMENT\n\nSEC. 101. SHORT TITLE.\n\n    This title may be cited as the ``Improved Border Control and \nNarcotics Abatement Act''.\n\nSEC. 102. EXPANDED BORDER PATROL AND SOUTHWESTERN REGION DEPLOYMENT.\n\n    (a) Increased Personnel.--The Attorney General, in each of the \nfiscal years 1995 and 1996, shall increase by no fewer than 700 the ",
      "source_length": 16602,
      "reference": "TABLE OF CONTENTS: Title I: Border Personnel, Training and Infrastructure Enhancement Title II: Asylum Reform Title III: Criminal Alien Deportation and Enhanced Prisoner Transfer Immigration Law Enforcement Act of 1993 - Title I: Border Personnel, Training and Infrastructure Enhancement - Improved Border Control and Narcotics Abatement Act - Authorizes appropriations and increases personnel levels for: (1) the Border Patrol; and (2) land border inspectors. Provides for: (1) primary deployment of such personnel on the Southwest border of the United States; (2) hiring preference for bilingual Border Patrol agents; and (3) improved training and improvement of border crossing infrastructure. Authorizes appropriations for Immigration and Naturalization Service technology and equipment acquisition. Establishes in the Treasury the Immigration Law Enforcement Fund. Creates a border crossing user fee. Title II: Asylum Reform - Executive Order Enhanced Consideration Revocation Act - Amends a specified Executive Order to partially revoke a provision with respect to asylum claims based upon birth control policies. Title III: Criminal Alien Deportation and Enhanced Prisoner Transfer - Criminal Alien Deportation and Enhanced Transfer Act of 1993 - Amends Federal criminal law to provide for a judicial order of deportation in the sentencing of an alien convicted of certain aggravated felonies. Authorizes the Secretary of State with the Attorney General to negotiate agreements with foreign countries for home-country incarceration of aliens subject to U.S. deportation. Authorizes appropriations. Amends the Immigration and Nationality Act to: (1) make an alien convicted of an aggravated felony ineligible for suspension of deportation and status of adjustment; and (2) prohibit the waiver of exclusion for an alien convicted of an aggravated felony.",
      "generated": "we report the results of a study of the influence of the thickness of a channel on the performance of a high speed bridge .<n> we find that a channel with thickness of at least three times the width of the channel has better performance than a channel of the same thickness but with thickness less than twice the width . <n> high speed bridges , or hsbs , were first constructed in the 1960s to improve the transport of hazardous materials @xcite . during the last decade<n> , they have been used to improve transport in a variety of applications , such as earthquake prediction @xmath0 , chemical and biological control @x , earthquake prediction of materials , and prevention of landslides . in the early 1990s , a group of scientists at the university of california , berkeley ,<n> submitted a proposal to construct a hsb with a thickness of about three times its width , based on the idea of using a dispersive barrier to confine an object moving at a constant speed . a few years later , the berkeley group published a feasibility study of such a structure @x<n> . the feasibility study showed that a high density of dispersively confined objects could be achieved , with we address the following question : is there a conflict of interest in the interpretation of the clause [ 1 ] ? we show that there is no conflict in the definition of the term  essential ' in section 4 : a ) . for the purposes of section 4<n> , the essential value is defined as the ratio of the total amount of money spent by the state to that of the district in which the experiment is carried out . '' <n> we prove that for the case of the experiment carried out by the university of california , berkeley , under the guidance of the director of national security , and under the direction of the acting director of operations , there is an error in the evaluation of the value of this sum . <n> * keywords : * _ essential value _ , clause 4.1.1 , section 4.1.2 , we show that in the case of an alien who is a minor in the united states of america , the lower bound on the sum of the squares of his birthplace and birthplace distances from the center of that country is : ( 1 ) .. the number of illegal aliens in state and local facilities is estimated to be about 4 million based on the most recent data from the us census bureau .<n> about half of the illegals are concentrated in high - density areas near large metropolitan areas , and about one - third are concentrated near or near high - schools . of these , about half are concentrated on high - school cliques , while the remaining ones are in the neighborhood of schools , city limits , or high school dropout centers . <n> about one third of all illegals in the state of arizona are concentrated around large cities , with about one quarter in the neighborhoods of high schools and dropout centers and the remaining one - quarter in neighborhoods of low schools and off the streets , according to a recent study by the national institute of standards and technology ( nimt ) based on data from 2003 to 2008 . the study focused on the statistics of the distribution of the numbers of people in different categories : high school , high school clique , dropout center and high school population . based on these statistics , the study found that about one in three high school and dropout center illegals reside in neighborhoods where at least one person is in state or local facilities ",
      "metrics": {
        "rougeL": 0.1093935790725327,
        "bertscore_f1": 0.7742403149604797,
        "latency": 4.504242181777954
      },
      "selection_reason": "worst_bertscore"
    },
    {
      "sample_id": 35,
      "doc_id": "dev_longform_355",
      "source_preview": "SECTION 1. SHORT TITLE; TABLE OF CONTENTS.\n\n    (a) Short Title.--This Act may be cited as the ``Temporary Tax \nHoliday and Government Reduction Act''.\n    (b) Table of Contents.--The table of contents of this Act is as \nfollows:\n\nSec. 1. Short title; table of contents.\n                      TITLE I--PAYROLL TAX RELIEF\n\nSec. 101. Extension of payroll tax holiday.\n                      TITLE II--DEFICIT REDUCTION\n\n        Subtitle A--Reform of Federal Benefits for Millionaires\n\nSec. 201. Ending u",
      "source_length": 17140,
      "reference": "Temporary Tax Holiday and Government Reduction Act - Amends the Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act of 2010 to extend through 2012 the 2% reduction in employment and self-employment tax rates. Amends the Internal Revenue Code to impose a 100% tax on excess unemployment compensation, as defined by this Act, received by certain high-income taxpayers. Amends the Food and Nutrition Act of 2008 to render ineligible for the supplemental nutrition assistance program (SNAP), formerly food stamps, any household in which a member receives income or assets with a fair market value of at least $1 million. Amends title XVIII (Medicare) of the Social Security Act to: (1) increase Medicare Part B and D premiums for Medicare beneficiaries with adjusted gross incomes over $750,000, and (2) extend through 2022 the freeze on the inflation adjustment to the income threshold for the Medicare premium subsidy eligibility. Requires the Director of the Office of Management and Budget (OMB) and the Director of the Office of Personnel Management (OPM) to determine the number of full-time employees employed in each federal agency. Prohibits a head of a federal agency from hiring more than 1 employee for every 3 full-time employees who leave employment in such agency until OMB and OPM make a determination that the number of full-time federal employees is 10% less than the initial level determined by OMB and OPM. Extends the freeze on the pay of federal employees through 2015. Provides that such extended pay freeze applies to legislative branch employees, including Members of Congress. Amends the Balanced Budget and Emergency Deficit Control Act of 1985 to reduce levels of discretionary spending for FY2013-FY2021. Buffett Rule Act of 2011 - Amends the Internal Revenue Code to allow taxpayers to donate an amount (not less than $1), in addition to any tax owed, which shall be deposited in the general fund of the Treasury and transferred to an account used to reduce the public debt.",
      "generated": "we address the question as to whether there is a relationship between the amount of compensation received by an individual and its membership in an association .<n> we show that the answer is negative . <n> * keywords : * association , income , unemployment . this is an attempt to answer the following question : what is the number of full-time employees of an agency ? <n> the answer is : there are two distinct cases . in the first case , each agency employs a number of employees that is determined by the determination of the state of war or other national concern .<n> the second case is the case in which an agency employs many employees , and an arbitrary number of them are employed . we consider the following question : what is the minimal amount of non - security authority required in order to guarantee the security of a country ?<n> the answer to this question is : (i ) for the security authority ; ii ) the budget authority . <n> iii ) : for the nonsecurity authority , the following amounts are required : ( i ) in the first case , in addition to the state budget , there is an additional penalty of @xmath0 per cent , and ( ii ) there are additional constraints imposed on the form of the budget ; ( iii ) if the non security authority can be shown to be guaranteed by a law of nature , then there is a possibility that it can be proved that it is guaranteed by nature ; and ( iv ) it is not necessary to establish the existence of the law of the nature .<n> + + _ key words _ : nonsecurity authorities ; nonsecurity category ; security category(s ) authority + + department of mathematics , king s college london + mile end road , london , wc2r 2ls , u.k  the @xmath0-title of this chapter is based on : a ) section .<n> [ thm]algorithm ; b ] section.[thm ]",
      "metrics": {
        "rougeL": 0.15434083601286172,
        "bertscore_f1": 0.7802408933639526,
        "latency": 4.671656131744385
      },
      "selection_reason": "worst_bertscore"
    },
    {
      "sample_id": 19,
      "doc_id": "dev_longform_404",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Social Security Number Protection \nAct of 2005''.\n\nSEC. 2. FINDINGS.\n\n    The Congress makes the following findings:\n            (1) The inappropriate sale or purchase of Social Security \n        numbers is a significant factor in a growing range of illegal \n        activities, including fraud, identity theft, and, in some \n        cases, stalking and other violent crimes.\n            (2) While financial institutions, health care provid",
      "source_length": 15403,
      "reference": "Social Security Number Protection Act of 2006 - Amends title II (Old Age, Survivors and Disability Insurance) of the Social Security Act (SSA) to make it unlawful for any person to sell or purchase a Social Security number in a manner that violates a regulation promulgated by the Federal Trade Commission (FTC). Directs the FTC to promulgate regulations restricting the sale and purchase of such numbers and any unfair or deceptive acts or practices involved in such a sale or purchase. Requires such regulations to be no broader than necessary to: (1) provide reasonable assurance that Social Security numbers will not be used to commit or facilitate fraud, deception, or crime; and (2) prevent an undue risk of bodily, emotional, or financial harm to individuals. Requires such regulations also to include exceptions which permit the sale and purchase of Social Security numbers to the extent necessary for: (1) law enforcement, national security, and public health purposes; (2) research conducted for the purpose of advancing public knowledge, subject to certain conditions; and (3) legitimate consumer credit verification, if the numbers used are redacted in accordance with uniform redaction standards established by the FTC in such regulations. Requires exceptions also for the sale and purchase of such numbers to the extent: (1) necessary in emergency situations to protect the health or safety of one or more individuals; and (2) consistent with an individual's voluntary and affirmative written consent to the sale or purchase of his or her number. Prescribes enforcement requirements. Authorizes states to bring civil actions on behalf of state residents in a U.S. district court to: (1) enjoin an act or practice; (2) enforce compliance with the regulation; (3) obtain civil penalties in an amount of $11,000 per violation, up to a total of $5 million; or (4) obtain other appropriate legal and equitable relief. Allows the U.S. Attorney General to institute a criminal proceeding for a violation of this Act.",
      "generated": "we address the following question : is there a restriction on the numbers that can be used in a financial transaction ?<n> specifically , we show that the number may not be used as a proxy for the identity of an individual , or for the number of an application , nor does it suffice to consider the number to be the same for each application . <n> our main result is that : a ) there is no _ a priori _ restriction on numbers .<n> b ) the numbers may be used for an application only if they are the same as the numbers used in the application ; and c ) for an individual to have a number , they must have a valid financial account . '' [ [ section ] ] in recent years , there has been a growing interest in the number - theoretic issues . in particular ,<n> the number theory has been the object of considerable recent attention , partly because of its connection to financial markets , and partly due to its relation to the so - called  _ secret number problem _ '' , i.e. , the problem of identifying numbers in financial transactions . from a practical point this case concerns the interpretation of a stipulating that an individual has a right to a fair and uniform treatment by an act of a governmental body .<n> specifically , the case concerns a regulation of a district court which determines whether or not an individual can be held to be amenable to be punished for a violation of that regulation . <n> [ [ section ] ] the purpose of this case is to determine the interpretation and applicability of the following regulations : ( i ) the following : _ a ) _ the regulations of the city of columbia , sc , usa , and of the state of new york , ny , as follows :<n> _ ( ii ) * a * _ : the regulations provide for the establishment of a new regulation of an individual s right to receive a uniform and fair treatment by a government body ; and _ iii ] * c * : * the regulations determine the severity and nature of the harm that could be caused to an individual as a result of the violation of the regulations . in particular , _<n> ( iii )*a ) determines the severity of the penalty that may be imposed on an individual for we show that the motion of the clerk of the superior court for the district of tennessee is invalid due to the following : ( i ) the motion to stay the final disposition of the action brought under (i ) and ( ii ) may not be stayed ; ( iii ) there exists a motion to intervene in the (ii ) case .",
      "metrics": {
        "rougeL": 0.16304347826086957,
        "bertscore_f1": 0.7819750308990479,
        "latency": 4.290544271469116
      },
      "selection_reason": "worst_bertscore"
    }
  ]
}