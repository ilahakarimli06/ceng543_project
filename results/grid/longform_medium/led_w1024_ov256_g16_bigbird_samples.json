{
  "config": {
    "model": "google/bigbird-pegasus-large-arxiv",
    "model_family": "BigBird-Pegasus",
    "attention": "default",
    "window_size": 1024,
    "overlap": 256,
    "global_tokens": 16,
    "category": "longform_medium"
  },
  "summary_stats": {
    "total_samples": 60,
    "avg_rougeL": 0.1217538862168305,
    "avg_bertscore": 0.8235261529684067,
    "min_rougeL": 0.050768203072812296,
    "min_bertscore": 0.7725192904472351
  },
  "samples": [
    {
      "sample_id": 0,
      "doc_id": "dev_longform_169",
      "source_preview": "the research on stellar oscillations within the framework of gr goes back to the early studies of chandrasekhar from almost half a century ago @xcite .\nthe field continues to attract great interest , because the investigation of stellar oscillations can reveal the inner structure of dense stars and shed light on the equation of state of superdense matter . in this paper\nwe focus exclusively on radial oscillations , for which the assumption of spherical symmetry holds . while radial oscillations ",
      "source_length": 16608,
      "reference": "we construct stellar models of hadron stars and hybrid stars and calculate the frequencies of their lowest radial mode of vibration . chandrasekhar s equation for radial oscillations is generalized for stars with internal electric fields and earlier versions of that generalization are simplified . for the hybrid stars a gibbs construction is employed . it is found that the softening of the equation of state associated with the presence of deconfined quarks reduces the oscillation frequency . we show that a slight charge inbalance should lead to increased maximum mass , decreased central density and lower oscillation frequencies .",
      "generated": "we study radial oscillations of hybrid stars with a gibbs construction and realistic equations of state for the quark and hadronic phases . we derive the oscillation equation and present first numerical results .<n> in contrast to previous studies , we investigate charged stars , because we show that the presence of a slight charge inbalance may help to reconcile soft equation of state with observations of massive pulsars . furthermore , an enhancement of the oscillation period at given central baryon density is observed . in our analysis<n> we also assume that the net charge is rather small , so that the star is not destroyed by the coulomb force . we study the equilibrium properties of dense matter in the vicinity of compact astrophysical objects , such as compact stars , neutron stars and black holes .<n> in particular , we focus on the conditions of hydro - electrostatic equilibrium , where the enclosed electric charge is equal to the total charge of the system . in this case<n> einstein s equation can be reduced to a relativistically invariant equation of motion , which can be solved by perturbation theory . for the hadronic phase we use a mit bag model with the free energy set tm1 . <n> compact stars are considered to be excellent laboratories for the study of the properties of strongly interacting many - body systems @xcite . due to their compactness<n> , they can be studied in great detail in stellar evolution codes , and thus constitute a useful model for the description of the early stages of the evolution of a compact star . among other things , compact stars can be used as laboratories for testing the standard model of particle physics , as they are believed to be the building blocks of black holes and can form the core of neutron stars . however , in spite of their compactity , the interior of compact stars is very hot and dense  we consider the pulsation of a spherically symmetric fluid in an electric field .<n> the perturbations of the stress - energy tensor obey einstein s equation . for the case of the schwarzschild metric ,<n> the enclosed electric charge is given by the differential equation for the electric field derived by bekenstein . in this paper<n> , we derive a new , more compact , version of the einstein - maxwell equations for the charge , which are valid in the regime of strong electric fields . as an example , for a spherical fluid in the presence of a strong electric field we calculate the amplitudes and the frequencies of the oscillations of the enclosed charge . <n> _ introduction._pulsations of fluid waves are ubiquitous in nature @xcite and play an important role in fluid dynamics , especially in the stabilization of ship propulsion systems , as well as in the dynamics of oil platforms , chemical reactions , and oceanography . despite their widespread use , there are still many open questions regarding their fundamental nature , e.g. , about their stability , or whether they can be described by adiabatic equations , such as einstein we construct hadronic models of hybrid stars , where the quark matter equation of state ( eos ) is given by the brueckner - hartree - fock approximation .<n> we find that the presence of the coulomb interaction augments the masses and reduces the frequencies of the fundamental radial mode . at the onset of the phase transition<n> there is a kink in the frequency curve , which is caused by the density jump at the phase boundary . <n> stars with strong chromo - magnetic fields ( cmf s ) can be used as laboratories to study the properties of strongly coupled quark - gluon plasmas ( qgp ) @xcite . in cmf<n> s the pressure is proportional to the chemical potential , @xmath0 , while in qgps it is related to the pressure by the chemical momentum tensor , h@xmath1 . for a given chemical potential<n> the pressure of the qgp depends on the chemical composition of the plasma . as a result ,<n> a pressure - temperature ( pt ) phase diagram appears in the space of chemical potentials , as shown in fig . [<n> fig : pt](1 ) we construct models of rotating hybrid stars , in which deconfined quarks are at the center of the star .<n> the presence of the quarks reduces the oscillation frequencies of the fundamental radial mode . at the onset of the phase transition<n> there is a kink in the frequency curve , which is shifted to lower values . <n> [ [ section ] ] recent observations @xcite , indicate that a large fraction of stars with masses above @xmath0 have a baryon content of more than one baryon per unit mass . in order to explain this observation<n> , it is necessary to assume the existence of exotic matter , such as supermassive black holes , or more generally , massive compact objects with a large mass , rotating about their axis . for a compact object ,<n> the gravitational mass is much larger than the baryon density , and the star can be considered to be a hybrid star , consisting of a black hole and a supermassive quark star ( sqm ) . as a result of the strong coulomb repulsion , the star is said to be _ charged _ : it has a baryonic core , but in this letter , we address the question of the correct expression for the surface tension of a spherically symmetric fluid as obtained by chanmugam , gondek - rosinska , bielich , and negreiros .<n> we show that this expression is in contradiction to the one found in a recent publication , which we believe to be wrong . <n> spherical symmetry is one of the most important properties of a fluid . for a fluid of spherical particles ,<n> spherical harmonics of radius @xmath0 are the only constants in the equation of state ( eos ) @xcite . in the limit of a homogeneous fluid<n> , the eos reduces to the schrdinger equation for the velocity of the fluid , where the velocity is given by the surface integral of the surface multiplied by a spherical harmonic function . as a result , in the thermodynamic limit , a fluid is said to be spherical if the surface is smooth , while it is  flat '' if it has a sharp surface . on the other hand , if the fluid is dense , as it is for a hydrogen atom , then a spherical surface is formed , i.e",
      "metrics": {
        "rougeL": 0.0812274368231047,
        "bertscore_f1": 0.8302058577537537,
        "latency": 4.907804250717163
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 1,
      "doc_id": "dev_longform_675",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Insurance Non-Discrimination for \nSurvivors Act''.\n\nSEC. 2. DEFINITIONS.\n\n    In this Act, except as otherwise expressly provided:\n            (1) Course of conduct.--The term ``course of conduct'' \n        means a course of repeatedly maintaining a visual or physical \n        proximity to a person or conveying verbal or written threats, \n        including threats conveyed through electronic communications, \n        or threats implied b",
      "source_length": 17309,
      "reference": "Insurance Non-Discrimination for Survivors Act - Prohibits an insurer from denying or terminating an insurance policy or health benefit plan, restricting or excluding coverage for losses or denying a claim, or adding a premium differential to any policy or health benefit plan on the basis that the insured (or any employee or any person with whom the insured is known to have a relationship or association) is the subject of, or incurs a claim related to, domestic abuse. Prohibits: (1) an insurer from denying or limiting payment to an insured who is the subject of abuse if the claim for payment is a result of the abuse; (2) an insurer or health carrier from terminating health coverage for a subject of abuse because coverage was originally issued in the name of the abuser and the abuser has divorced, separated from, or lost custody of the subject or the abuser's coverage has terminated and the subject does not qualify for an extension of coverage; and (3) any person employed by or contracting with an insurer or health benefit plan to use, disclose, or transfer specified information (including regarding abuse status) without the subject's consent. Requires: (1) insurers to develop and adhere to written policies specifying procedures to be followed to protect the safety and privacy of a subject of abuse; and (2) an insurer that takes an action that adversely affects a subject of abuse to advise that applicant or insured in writing of the specific reasons for the action.",
      "generated": "we consider the following question : under what conditions can an individual be forced to participate in an activity that is inconsistent with his or her health policy ?<n> we show that the answer is : 1 . <n> a ) an individual has the right to engage in any commercial activity that disagrees with his / her health insurance .<n> 2 . the converse :  a ) the converse is true . ' ' <n> 3 . an individual is not required to be a party to which the policy is affiliated in order for the individual to receive health benefits . we address the question of whether a health plan satisfying its own form of group solvency can exclude coverage for an individual who engaged in an intimate relationship with another person .<n> we show that : 1 . <n> the existence of a group plan is a sufficient condition for group solvency to be satisfied ; 2 . in a general case ,<n> there are two classes of group plan participants :  individuals ' and  floaters ' , the latter being defined as those who are not part of a larger group , such as a corporation , a union of several entities , or a non - partnership consisting of a number of individuals , each of which has its own group plan ; 3 . the floaters , on the other hand , are those who belong to a group ;<n> they are defined as either the members of the group or the floaters themselves ; and they are in fact the same class of plan participants as the group members , i.e. , they belong to the same group . we consider an abuse - avoidance plan where an insured is prohibited from transferring his or her personal wealth for the purpose of obtaining a benefit .<n> we address the following issues : 1 . <n> the insurer must provide evidence in support of its claim that the subject of abuse has committed an abuse- of the proposed plan ; 2 . the insured and the agent who brought the abuse- claim have conflicting interests in making such a claim ; 3 . this paper is concerned with the protection of an individual who has been the victim of an act of actuarial misconduct by an insurer .<n> specifically , we deal with the following situation : ( i ) the individual has been a regular contributor to the court system for a long time , ( ii ) he has suffered an action of omission or commission of any kind by an insurance company , and ( iii ) there has been an attempt by the insurer to induce the individual to change his or her opinion about the claim , including making a false claim and a false statement about the value of the insurance policy . <n> the main result of the case is that if the individual acts or does not act in a way that is inconsistent with his / her own fitness as a witness and/or with the laws of nature , then the court has no power to protect the individual from such an action .",
      "metrics": {
        "rougeL": 0.1793478260869565,
        "bertscore_f1": 0.8014734983444214,
        "latency": 4.3985655307769775
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 2,
      "doc_id": "dev_longform_30",
      "source_preview": "three years after the first identification of the x - ray afterglow from a gamma ray burst ( grb ) ( costa et al . , 1997 ) , the nature of gamma ray bursts progenitors remains uncertain .\nthe most widely discussed theoretical models for grbs consider vastly different scenarios both in terms of the progenitors and environment .\nif the grbs originate from neutron star - neutron star or neutron star - black hole mergers ( narayan , paczynski and piran 1992 ) then , for about a half of all grbs , t",
      "source_length": 17577,
      "reference": "we report the detection ( @xmath0 significance level ) of a strong iron emission line in the x - ray spectrum of the afterglow of grb 000214 ( `` valentine s day burst '' ) observed by bepposax . an emission line feature was observed with a centroid energy of @xmath1 kev which , if interpreted as k@xmath2 emission from hydrogen - like iron , corresponds to a redshift of z=0.47 . the intensity ( ew@xmath3 kev ) and duration ( tens of hours ) of the line give information on the distance , from the burst region , of the emitting material ( @xmath4 cm ) and its mass ( @xmath5 ) . these results are not easily reconciled with the binary merger and hypernova models for gamma ray bursts , because they require large amounts of mass ( about @xmath6 ) , at large distances ( @xmath7 ) , and at newtonian speeds .",
      "generated": "we report on the detection of an iron emission line in the x - ray spectrum of the afterglow of the gamma ray burst grb 000214 (  valentine s day burst '' ) observed with the bepposax satellite .<n> the line , at @xmath0 , has a fwhm of @ xmath1 km s@xmath2 and a rest - frame equivalent width of @xcite , implying a redshift of 0.58 . the observed spectrum can be described by a power - law with a photon index of 2.17 , and an absorption column density of n@xcite ( for an assumed cosmological model ) , or by a blackbody with a temperature of n=5.7 kev ( for a cosmological model with cosmological density profile ) or by an absorption component with n=5.6 kev and a temperature in the range of 10 kev to 30 kev . in the latter case ,<n> the observed line flux is consistent with that expected from an iron line produced in a supernova ( sn ) explosion at a cosmological redshift . <n> # 1#2#3#4#1 , a&a , * # 2 * , # 3 ( we report on the detection of an iron k@xmath0 emission line from the x - ray afterglow of grb 000214 , based on a pointed bepposax observation performed about 12 hours after the burst onset .<n> the observed line flux is @xmath1 erg s@xcite , which corresponds to the equivalent width of @x 0.31 kev , if the line is assumed to be emitted by the same material responsible for the gamma - ray emission in the prompt event , i.e. , the grb ejecta . <n> the lack of an optical or ir counterpart to a grb may result in extinction in a dense surrounding medium ; therefore , searching for emission lines in the afterglows of these grbs is especially promising . in this paper , we present the results of the analysis of the data obtained from a pointed observation performed by beppo sax . we report the detection of an emission line at @xmath0 kev in the spectrum of the afterglow of grb 000214 .<n> the line appears in both the lecs and mecs spectra of the source , obtained with the bepposax satellite , and can be well fitted with a power - law of photon index @xcite , a gaussian line , or a combination of the two . <n> this is the second well - observed afterglow after ngc 7469 ( piro 1999b ) , which showed a similar emission line in its afterglow spectrum ( johnson & narayan 1998 , mnras , 439 , 1661 ) and was subsequently confirmed by observations with the hubble space telescope ( _ hst _ , 1999 , piro , 000 214 ) in the optical and x - ray bands . in both cases<n> the spectral energy distribution is consistent with that expected from the emission of a black hole with a mass of 10@xmath1 , as suggested by the chandrasekhar - fermi formula ( iccf , komatsu & neyman , 2000 , annals of physics we report the detection of an emission line in the mecs spectrum of the afterglow of grb 000214 .<n> the line has an energy of @xmath0 kev , and its redshift is measured to be between 0.47 and 0.55 , depending on whether the line is assumed to be a k@xmath1 edge or not . this is the second case of an iron line in afterglows , after grb 970508 , where the line was not detected . <n> we present the results of an analysis of the spectral energy distribution ( sed ) and of the time evolution of the flux , using data obtained with the multi - object spectrometer ( mecs ) on the _ hubble space telescope _ ( _ hst _ ) . in the course of the analysis , we determined the redshift of the source and found that the flux decreased by about a factor of two in the first 30 ks after the burst , i.e. , much too fast to have been due to a reburst . we conclude that the most plausible explanation for the appearance of this line is that it is due to an iron emission line at a redshift we report on the detection of the iron line in the reburst of grb 000214 . the line luminosity and the duration of the event are consistent with those of the other bursts with detected iron lines ( grb 970508 , grb 021211 , and grb 990510 ) .<n> we show that the line is emitted by material moving at sub relativistic speeds ( @xmath0 ) with respect to the plane of the sky . if the material is iron - rich , it must be located at large distances from the burster , i.e. it must have formed well before the burst . in the standard model of gamma ray bursts ( grbs )<n> , the prompt emission is due to the collapse of a massive star to a black hole ( bh ) or a neutron star ( ns ) ( ghisellini et al . , 1999 , piro et al., 1999 and lazzati , 2000 , apj , 545 , l67 ) and , subsequently , to a supernova ( sn ) explosion @xcite . however , in recent years , there has been growing evidence that the prompt we report the detection of cobalt and nickel absorption lines in the x ray afterglow of grb 990123 , obtained with the beppo - sax and rosat telescopes , respectively .<n> the line width of @xmath0 km s@xmath1 is consistent with the presence of outlying material , either from the progenitor s formation process or from the ejecta of a peculiar core collapse supernova ( sn ) , if the progenitor mass is in the range @xxmath2 , or from a primordial gas cloud if it is larger than this limit . in the case of nickel absorption ,<n> the observed line width is consistent , within the uncertainties , with that expected from the nickel abundance . <n> grb 980123 is the first neutron star ( ns ) for which the iron mass fraction has been measured , and the first grb afterglow for which a cobalt absorption line has been detected , at a level comparable to the solar value . the iron - peak element [ fe / h ] in the spectrum of the x <n> rays is found to be fe xxv + xxvi @xcite , while the nickel - peak elements [ ni / fe",
      "metrics": {
        "rougeL": 0.11531531531531533,
        "bertscore_f1": 0.8531829118728638,
        "latency": 4.682822227478027
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 3,
      "doc_id": "dev_longform_300",
      "source_preview": "next - to - leading order in  ( ) corrections in di - boson production are large at the cern lhc and sizeable at the fermilab tevatron ( see for example @xcite ) .\nrun  i physics analyses ( i.e. , @xcite ) at the tevatron have employed constant @xmath1-factors to approximate corrections . with the increased energy and luminosity of run  ii and the new energy regime that will be probed with the cern lhc , simulations incorporating higher order corrections will be of increased importance .\ndiffere",
      "source_length": 29246,
      "reference": "we present an algorithm for unweighted event generation in the partonic process @xmath0 with leptonic decays at next - to - leading order in . monte carlo programs for processes such as this frequently generate events with negative weights in certain regions of phase space . for simulations of experimental data one would like to have unweighted events only . we demonstrate how the phase space from the matrix elements can be combined to achieve unweighted event generation using a second stage monte carlo integration over a volume of real emissions ( jets ) . observable quantities are kept fixed in the laboratory frame throughout the integration . the algorithm is applicable to a broader class of processes and is cpu intensive .",
      "generated": "we present an algorithm for unweighted event generation in hadronic di - boson production at hadron colliders .<n> the algorithm makes use of the matrix elements from the baur , han , and ohnemus ( bho ) integration package , which is an extension of the phase space slicing method @xcite . in this method , a cylinder of jets defined by a transverse momentum cutoff @xmath0 is used to partition event generation into a subprocess where the real emission has sufficient transverse momentum to be potentially observable ( called 1 jet ) and another subprocess which has sufficiently small transverse momentum such that it is taken as unobservable . there are no divergences in the 1 jet cross - section so these events all have positive weights and un weighted event generation may be accomplished by applying monte carlo hit - and - miss . the approximations break down before the volume can be increased sufficiently to render all event weights positive . here<n> we present the algorithm for the case of the drell - yan process with next - to - leading order in ( ) corrections . we present an algorithm for the analytic integration of large volumes of soft and collinear real emissions .<n> the algorithm is an extension of the phase space slicing method , wherein a cylinder of jets defined by a transverse momentum cutoff @xmath0 is used to partition event generation into a subprocess where the real emission has sufficient transverse momentum to be potentially observable ( called 1 jet ) and another subprocess which has sufficiently small transverse momentum such that it is taken as unobservable . in this paper<n> we present the details of the algorithm and apply it to the production of hadrons by neutrinos at the large hadron collider ( lhc ) in proton - antiproton collisions at 14 tev center - of - mass energy . <n> 0.0 in 6.0 in 8.75 in -0.5 in = cmssbx10 scaled 2 to * event generation with a jet volume integration method * .5 in greg w. anderson@xmath1 , stephen g. naculich@xcite , and william j. strassler@x .2 in _ @xcite @x_department of physics , university of wisconsin , madison , wi 53706 we report on an extension of the phase space slicing method for inclusive jet production at the large hadron collider ( lhc ) .<n> the method incorporates a volume of real emissions phase space , which allows for the treatment of multi - gluon emission . in this paper<n> , we discuss the algorithm and present results for the case of @xmath0 production with leptonic decays . <n> lepton flavor violation ( lfv ) is a characteristic feature of quantum chromodynamics ( qcd ) and is believed to play an important role in the dynamics of strong interactions at the lhc @xcite . at high energies ,<n> the production of leptons in association with jets is expected to be dominated by gluon jets , so that it is important to have a method for calculating the production cross - section in a region of phase space where the soft and collinear divergences of qcd do not overlap (  soft emission '' region )<n> . however , in the soft emission region , the calculation becomes non - perturbative , and it is necessary to incorporate the leading pole approximation ( lsa ) to ensure the cancellation of the divergences , as well as the we present results from a monte carlo simulation of @xmath0 production at the large hadron collider ( lhc ) .<n> the calculation is performed in the region of phase space where neutrinos are the only active degrees of freedom , and we use a cylinder of jets to define the observables . we find that the lhc will be able to place stringent constraints on @xcite , the majorana neutrino yukawa couplings , as well as constrain the neutrino mixing matrix elements . <n> lepton flavor violation ( lfv ) is one of the most important signatures of physics beyond the standard model ( sm ) in high energy collisions . in the presence of cp violation in the quark sector ,<n> the leptonic decays of the top quark are expected to be strongly suppressed , so that the observation of lfvs in the lepton sector is a crucial test of the sm and its extensions . to date<n> , there is no direct measurement of the cp violation parameter in the top sector . however , it is known that cp violation is present in the bottom sector in the form of anomalous magnetic moment ( amm ) violation , which is the dominant we present monte carlo simulation results for the determination of the cross - section for @xmath0 pair production at the large hadron collider ( lhc ) .<n> the results are based on the cteq4 m formalism for the fixed vector boson model , and include fixed charged lepton rapidities and missing transverse momenta , as well as jet veto constraints . <n> slac <n> pub8234 + hep - ph/9501287 + + + _ stanford linear accelerator center _<n> + davis institute for physics + university of california , davis , ca 95616 _ + the goal of the lhc is to search for the production of the higgs boson @xcite . at a center - of - mass energy of 7 tev and luminosity of 100 fb@xmath1<n> , it will be possible to study the production and detection of up to three standard model ( sm ) particles , namely the top quark , bottom quark and gluino . in the standard model the top and bottom quarks are produced in association with an energetic gluon , which decays into a higgs and a tau lepton  we present an algorithm for the evaluation of matrix elements in qcd .<n> the algorithm is based on the phase space slicing method , and is capable of dealing with both positive and negative event weights . as an example application we present results for the production of 0 and 1 jets in proton - proton collisions at the large hadron collider ( lhc ) at cern . <n> monte carlo simulations of qcd processes have shown that it is possible to obtain a reasonable description of the measured hadron - proton cross - section and in particular the anomalous magnetic moment ( amm ) of the muon @xcite . in this letter<n> we present the results of an alternative method for the calculation of the same quantity , which uses the matrix elements from the bonn - gatchina ( bho ) factorization theorem , but which is more efficient than the bho algorithm in dealing with the negative probability events associated with anomalous @xmath0 production . to appear in the proceedings of the international workshop on deep - inelastic scattering and related subjects , _ qcd02 : quark matter at the lhc and beyond _ , held in guanajuato , mexico , november we describe algorithms for the generation of events at the large hadron collider ( lhc ) with leptonic decays .<n> we also describe the effects of these events on the extraction of unweighted events . <n> leptonic @xmath0 decays have been proposed as a means of probing anomalous couplings at the lhc @xcite . in the standard model ( sm ) of particle physics ,<n> the couplings of interest are those which lead to the production of a lepton with transverse momentum larger than the sum of the masses of the quarks and leptons , i.e. , the  standard model couplings '' . at the tevatron and lhc<n> , it will be possible to measure these couplings , as well as the masses and widths of the vector bosons produced in the process , and so study the properties of the electroweak gauge bosons which are responsible for this coupling , such as the top quark and the higgs boson . however , in the minimal supersymmetric extension of the sm ( mssm ) , there are large deviations from the sm predictions , which can not be accounted for in the ms we present an algorithm for the generation of jets in @xmath0 annihilation into leptons and photons .<n> the algorithm is based on the phase space slicing technique , and the results are compared to those of the bho integration package . <n> monte carlo methods have been used with great success to generate leptonic and hadronic events at hadron colliders , such as the tevatron @xcite , the lhc ( cern sps , fermilab ) and the slac linear collider ( lhc , cern ) , to name a few [ 1 ] . in the standard model ( sm ) of particle physics , electroweak , chromo - electric and chromo - magnetic interactions are described by the higgs doublet model , which has been extensively tested against experimental data . however , in the sm , there are discrepancies in the values of the parameters entering the lagrangian , leading to possible deviations in the production cross - sections of electroweak gauge bosons from their standard model predictions . to resolve these discrepancies ,<n> it is necessary to consider new physics contributions to the electroweak processes . among the most important new physics we study the effect of a nonminimal coupling on the @xmath0 dependence of the anomalous magnetic moment of the muon .<n> we find that for a value of the coupling which is in agreement with the experimental data , a value for the magnetic moment much larger than the experimental upper limit can be obtained . in recent years<n> there has been an increasing interest in the measurement of the magnetic moments of muons @xcite . for the case of the proton ,<n> the results obtained by the d experiment @xxcite are in good agreement with those from the cern lep and the slac linear collider ( lhc ) . however , for the nucleus , the results from the fermilab tevatron collider have been less satisfactory . <n> there are two main reasons for this discrepancy : 1 ) the standard model ( sm ) of particle physics does not take into account all the details of the nucleon structure , and 2 ) there are non - minimal couplings between quarks and gluons , which are not included in the sm equations of motion . as a result , there are a number of theoretical problems which arise when one tries to calculate the",
      "metrics": {
        "rougeL": 0.06619385342789598,
        "bertscore_f1": 0.8253258466720581,
        "latency": 5.656315326690674
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 4,
      "doc_id": "dev_longform_281",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Thermal Energy Cooling and Heating \nAct of 2009''.\n\nSEC. 2. CREDIT FOR QUALIFIED DISTRIBUTED THERMAL STORAGE PROPERTY \n              INSTALLED IN A PRINCIPAL RESIDENCE.\n\n    (a) In General.--Subsection (a) of section 25D of the Internal \nRevenue Code of 1986 is amended by striking ``and'' at the end of \nparagraph (4), by striking the period at the end of paragraph (5) and \ninserting ``, and'', and by adding at the end the following new ",
      "source_length": 10840,
      "reference": "Thermal Energy Cooling and Heating Act of 2009 - Amends the Internal Revenue Code to allow: (1) a residential energy efficient property tax credit for 30% of expenditures for distributed thermal energy storage property installed in a principal residence; (2) a 30% energy tax credit for investment in qualified distributed thermal storage property prior to 2017; and (3) financing of qualified distributed thermal energy storage property with new clean renewable energy bonds.",
      "generated": "in this paper , we investigate the relation between thermal energy and the amount of heat that can be extracted from a liquid .<n> we show that a liquid can be very efficient at storing heat if it is cooled in such a way that the heat stored in the liquid is proportional to the square of the temperature of the fluid . (a ) for a distributed thermal energy storage property which is designed to deliver a minimum of 29,000tu per hour of installed thermal heat storage capacity for a minimum continuous period of 3 hours , available from 1 through 30 , or to reduce peak electrical demand of conventional mechanical cooling or equipment  ( b )  to any qualified facility for which the peak demand reduction for air conditioning property is determined based on demand ( service ) standards for residential and commercial air conditioning equipment , established under this section , and ( c ) to any company which has qualified heating or cooling property with respect to distributed heat storage property and which has not integrated any equipment which has operational cooling or conventional electrical equipment . <n> ( d ) the general-  for a qualified facility  which is a commercial or residential air conditioning system  ,  i.e. , for a specified specified residential or commercial airconditioning property  and for any service property which has a specified demand ( peak ) reduction for each 0.5 kilowatt peak of service for such property placed in service for a certain period of time ; ii. ]  iii. )<n> the (3)'-(",
      "metrics": {
        "rougeL": 0.1523809523809524,
        "bertscore_f1": 0.806591808795929,
        "latency": 3.7633659839630127
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 5,
      "doc_id": "dev_longform_255",
      "source_preview": "SECTION 1. SHORT TITLE; REFERENCES IN ACT.\n\n    (a) Short Title.--This Act may be cited as the ``Medicare Rural \nHospital Amendments of 1993''.\n    (b) References in Act.--Except as otherwise specifically provided, \nwhenever in this Act, an amendment is expressed in terms of an \namendment to or repeal of a section or other provision, the reference \nshall be considered to be made to that section or other provision of \nthe Social Security Act.\n\nSEC. 2. ESSENTIAL ACCESS COMMUNITY HOSPITAL (EACH) AM",
      "source_length": 16075,
      "reference": "Medicare Rural Hospital Amendments of 1993 - Amends title XVIII (Medicare) of the Social Security Act to extend and revise programs to assist rural hospitals under Medicare part A (Hospital Insurance). Authorizes appropriations. Amends the Omnibus Budget Reconciliation Act of 1987 to reauthorize and extend the rural transition grant program. Amends the Omnibus Budget Reconciliation Act of 1989 to extend regional referral centers. Revises Medicare-dependent, small rural hospital provisions under Medicare. Requires the Secretary of Health and Human Services to provide rural referral centers and Medicare-dependent, small rural hospitals which have been reclassified as urban the opportunity to decline such reclassification.",
      "generated": "in this paper , we address the question of whether there is a lower bound on the average length of stay at a particular facility for a certain patient .<n> we specifically address the following question : 1... how does the lower bound for the average hospital length for a given patient depend on the duration of stay ? <n> 2... what is the relationship between the length of a hospital stay and the amount of care that the hospital needs to provide ?<n> ..<n> the answer to the first of these questions depends on the definition of  acute care '' . in general ,<n> a hospital is said to provide acute care if it is able to treat at least one patient within a period of at least 72 hours . <n> the definition is as follows : a ) for an individual patient , the total number of hours that the individual needs to spend in order to be admitted to the hospital for treatment of that patient is equal to the total amount of time that the patient has spent in that hospital during that period of time , divided by the number of times the individual has been admitted to that hospital for that purpose . '' <n> b ) in section [ 1 ]  in this paper , we show that a hospital designated as an  essential facility '' in a rural area is not eligible for any of the following services : ( i ) primary health care ; ( ii ) long - term rehabilitation ; and ( iii ) home care .<n> we do this by showing that , under certain conditions , a hospital is eligible for these services if and only if it is located in an area bounded by ( 1 ) , ( 2 ) the area of the community where the hospital is located and ( 3 ) a certain threshold on the distance between the hospital and the nearest home for which there is an essential facility . we address the issue of whether there is a conflict of interest between the classification of a hospital as an extended care facility and the determination of the number of the hospital beds used for providing extended care . <n> 4 4 is amended because striking  and all that follows the following decision : in the above decision , the facility ( 1 ) meets the requirements of this sub(s ) and ( 2 ) applies as if it were a rural primary hospital . ( 3 ) in the decision of 1 ,<n> the facility fails to qualify as a sub for extended care services .<n> we resolve this problem by determining that the decision to assign a sub to a hospital is not affected by the failure of the facility to meet the requirements for extendedcare services , and we resolve the problem by assigning the facility as a primary hospital for the purposes of classification . [ 1 ] [ 2 ] 1] [ 3 ] 4 [ 4 ] 5 [ 6 ] 7 [ 8 ] 9 [ 10 ] 11 [ 12 ] 14 [ 15 ] 16 [ 17 ] a case is made in favour of a reclassification of hospital based on the principle of universality .<n> it is shown that : i ) a case can be made for the validity of the universal definition of the period of observation of a person . <n> ii ) the case can also be made that , in the case of a city with a population of at least 10,000 , the period is determined by the city s population ratio to that of its wards , i.e. , by the ratio of the total number of inhabitants to the total area of the city divided by the square root of the number of its inhabitants. iii ) there is a case for reclassifying such a city as being located in a neighbourhood of another city with the same population ratio and the same period . in this case<n> the period can be defined as the ratio between the periods of the two cities ; iv ) for such a hospital , such a period can not exceed the period determined for the city by a factor of more than two .",
      "metrics": {
        "rougeL": 0.07171314741035857,
        "bertscore_f1": 0.7725192904472351,
        "latency": 4.377660274505615
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 6,
      "doc_id": "dev_longform_639",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Incentivize Growth Now In Tomorrow's \nEntrepreneurs Act of 2017''.\n\nSEC. 2. SMALL BUSINESS START-UP SAVINGS ACCOUNTS.\n\n    (a) In General.--Subchapter F of chapter 1 of the Internal Revenue \nCode of 1986 is amended by adding at the end the following new part:\n\n          ``PART IX--SMALL BUSINESS START-UP SAVINGS ACCOUNTS\n\n``Sec. 530A. Small Business Start-Up Savings Accounts.\n\n``SEC. 530A. SMALL BUSINESS START-UP SAVINGS ACCOUNTS.\n\n    ",
      "source_length": 17532,
      "reference": "Incentivize Growth Now In Tomorrow's Entrepreneurs Act of 2017 This bill amends the Internal Revenue Code to create tax-exempt small business start-up savings accounts to pay for the start-up expenses of a business that does not employ more than 50 full-time employees during a taxable year. Cash contributions to such accounts are allowed up to the lesser of $10,000 or the amount of compensation includible in the taxpayer's gross income for the taxable year. (Start-up expenditures are paid or incurred in connection with: (1) investigating the creation or acquisition of an active trade or business; (2) creating an active trade or business; or (3) any activity engaged in for profit and for the production of income before the day on which the active trade or business begins, in anticipation of the activity becoming an active trade or business.)",
      "generated": "we show that the definition of a contribution to a local nonlocal business association is ambiguous . (i ) contributions to a small business start- up account with respect to which the individual and the business are treated as individuals . <n>  ( ii ) distributions from a business which is treated as a sole act of business within the meaning of section 408.040(a ) of the code , and which are treated by the individual who is the sole agent of the business , notwithstanding any other provision for the business which would be treated as an act of sole action by the beneficiary , the agent who receives the distribution from the business and the beneficiary under the above mentioned definitions of distributions , as well as any other distribution made by the business under the definition of distributions for which the business has been established , are not treated as individual s accounts for the account of this business for the year under consideration , but as distributions for the following years ; and , in the case of a joint distribution , such joint distribution for the years 2008 and 2009 , if the joint distribution is made by an individual with the same asset value , then the difference between the two distributions is of the order of @xmath0 .<n> the above definition of a distribution for a business is based on the fact that this paper deals with the avoidance of certain types of penalties in connection with the winding up of a small business . in particular , we deal with the following types of penalty : 1 . (g ) i.e. , the penalty determined by section 1(f ) for the calendar year in which the business is winding up , determined by substituting (1) such dollar amount , multiplied by (2) , at the time of writing , which includes such date or if such person is the only owner of the business , in such a manner as to account for the fact that the business has been winding up for some time , and 2 .<n> (2 ) the penalty for not writing the business in a way such that it is in proportion to the square of the square root of the number of shares held by the company , for which the attribution of the income to the original owner is not made , as is done in the case of small business ownerships , where the attribution is done as follows : the income of the original ownership is attributed to the author of the paper , @xmath0 , while the income for the author to write the attribution in this paper , we address the question of whether or not a small contribution to a limited company can be shown to be made with respect to a passive dividend in the ordinary dividend distribution of the limited company .<n> we show that the answer is negative for the case where the passive dividend is the only source of income for the limited business . <n> [ [ section ] ] the purpose of this paper is to answer the following question : 1 . for a passive investor in a small business , does it make a passive contribution to the income of the business ? '' <n> the passive investor is interested in a passive investment in the business in the sense that the passive income in the passive investment will be less than that of the asset  for which the passive asset is called . '' ] in section 4 of section 4 , it is stated that the amount of passive income that can be made is the same for an individual as for an entity . in section 5 of section 5 ,<n> it is defined that an entity is passive if and only if its passive income is less than the sum of its individual passive income and its aggregate passive income ; in particular , no passive investment is made if the individual",
      "metrics": {
        "rougeL": 0.11553273427471117,
        "bertscore_f1": 0.7972198724746704,
        "latency": 4.5954978466033936
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 7,
      "doc_id": "dev_longform_194",
      "source_preview": "the onset of irreversibility in physics is one of the great questions at the heart of statistical mechanics .\nthe second principle of thermodynamics in essence states that spontaneous processes happen in one direction , namely increasing entropy or decreasing free energy .\nboltzmann s h - theorem was aimed in proving this possibility starting from microscopic time - reversal mechanics , but , as he tragically had to realize , there is no way of doing that . in classical physics irreversibility e",
      "source_length": 28956,
      "reference": "we show that in a quantum system evolving unitarily under a stochastic quantum circuit the notions of irreversibility , universality of computation , and entanglement are closely related . as the state evolves from an initial product state , it gets asymptotically maximally entangled . we define irreversibility as the failure of searching for a disentangling circuit using a metropolis - like algorithm . we show that irreversibility corresponds to wigner - dyson statistics in the level spacing of the entanglement eigenvalues , and that this is obtained from a quantum circuit made from a set of universal gates for quantum computation . if , on the other hand , the system is evolved with a non - universal set of gates , the statistics of the entanglement level spacing deviates from wigner - dyson and the disentangling algorithm succeeds . these results open a new way to characterize irreversibility in quantum systems . _ keywords _ : entanglement entropy , chaos , irreversibility , quantum circuits",
      "generated": "we study the onset of irreversibility in quantum evolution starting from a completely disentangled state . we show that if the evolution is irreversible , the entanglement will be complex in the degrees of freedom in which the interactions are simple . in this sense irreversability is a complexity problem .<n> we posit that entanglement is not neutral ( like energy ) with respect to the degree of entanglement that is involved . we show that irreversibility is a property of the entanglement , not of the state . to this end<n> , we study the evolution of a state subject to a random unitary quantum circuit .<n> we find that the state is fully entangled if and only if the level spacing statistics of the reduced density matrix spectrum is wigner - dyson , showing a robust level repulsion . on the other hand , simple , removable entanglement possesses spectral fluctuations that follow , for instance , a poisson statistics . therefore , generic quantum ( unitary ) evolution is irreversible because of a specific pattern of entanglement . as we showed in a previous paper [ phys . rev . a * 89 * , 062302 ( 2014 ) ] , this phenomenon is understood in terms of the complexity of the entangled state , rather than in terms the amount of entanglement that a state is able to generate . <n> we consider a quantum system made of @xmath0 qubits , and we assume that the local unitaries are one- and two - qubit gates . the set containing the gates * h * ( hadamard ) and * t * ( phase gate ) is a we consider a quantum computer made of qubits , and subject to a random unitary quantum circuit .<n> we find that evolution obtained with the full unitary group by means of universal quantum computation is irreversible and the statistics of the level spacings of reduced density matrix spectrum is wigner - dyson , _ i.e _ , is complex . on the other hand , if the entanglement level spacing statistics is poisson , the disentangling algorithm succeeds , which means that the pattern of entanglement is not complex<n> . it is remarkable that reversibility arises with severe breaking of ergodicity . if the set of gates is not universal , not every state can be reached ; this is only possible if a rotation by an irrational angle is broken . <n> @xmath0department of physics , university of alberta , + edmonton , ab , canada t6 g 2j1 we study the von neumann and rnyi entropies of the reduced density matrix of a quantum state evolving with a stochastic quantum circuit .<n> we also study the entanglement properties of the state after the quantum circuit has been applied on it . <n> quantum computation is a powerful tool for simulating physical systems . in particular ,<n> quantum computers have been proposed to solve certain computational problems , such as factoring , that are intractable with classical computers @xcite . however , in order to implement quantum computation efficiently , it is essential that the underlying physical system can be prepared in a sufficiently large quantum state , so that the computational complexity can be reduced as much as possible . as a result<n> , quantum computation has been proposed as a promising alternative to classical computation , for example in the field of high - performance computing ( hpc ) , which aims to achieve an exponential speed - up of computation over classical computers . for hpc to be effective , the underlying system must have a sufficient number of qubits , or , equivalently , gates , to implement a large set of unitary operations , called quantum gates . a quantum circuit is a sequence of quantum gates that implements a given we show that entanglement cooling is an efficient method to generate maximally entangled states in a stochastic quantum circuit , even if the quantum circuits are not drawn from a universal set .<n> the efficiency of the algorithm is related to the statistics of the level spacing for the entanglement spectrum . <n> entanglement is one of the most intriguing features of quantum mechanics . in the quantum domain ,<n> it has been shown to be a useful resource for quantum information and computation @xcite . however , it is also known to be extremely fragile to decoherence , and it can even lead to a complete breakdown of the system . at the same time , there is a growing interest in using entanglement to generate non - classical states of matter , such as superpositions of states , entanglement of composite particles , or entangled photon states . among the different approaches , the one based on stochastic quantum circuits ( sqcs ) has been the most successful so far . here<n> , we will show that , despite its inherent difficulties , this method can be used to generate highly entangled states of a large class of quantum systems , for example , spin qubits , photons , ions , atoms we show that entanglement is not able to distinguish universal from non - universal sets of gates in a random quantum circuit .<n> in particular , if the random circuit is drawn from a universal set , the entanglement cooling algorithm always works , but if the circuit is not drawn from the same set of gates , entanglement will not be factorized , and the algorithm will reject the gate . in order to reach the completely factorized state , we actually consider the average of particular bipartitions of the system with the number of gates running from zero to infinity . [ [ introduction . ] ] introduction. + +<n> + + + / introduction.+ + + [ + + ] quantum entanglement is a useful resource for quantum information processing @xcite . however , to fully exploit it , one needs to understand how it is related to the properties of the underlying physical system . to this end<n> , it has been shown that entanglement can be used to distinguish between universal and non - universality sets of quantum gates @xmath0 , as well as between two - qubit and higher - dimensional entangled states , without relying on any of the assumptions on the physical system under consideration . on the other hand we propose an entanglement - based algorithm for quantum computing that does not require the computation to be performed on the state of the system .<n> instead , the algorithm is based on the observation that the state is a product of a random bipartition of qubits , and that it is necessary to increase the entanglement in order to reduce the reduced density matrix of the bipartition . <n> the idea of using entanglement to perform computation dates back to the work of heisenberg on fault - tolerant quantum computation @xcite . since then<n> , there has been a lot of interest in using entanglement as a tool for the design of quantum computers . in particular ,<n> quantum computers have been proposed to solve certain types of problems faster than their classical counterparts , _<n> i.e. _ , @xmath0 times faster on a classical computer @x<n> . however , in practice , it is not easy to implement an efficient quantum algorithm on a quantum machine , because the classical one requires a large amount of computation time . as a result , much effort has been devoted to the development of efficient quantum algorithms , such as the one proposed by elliott _ et al._@xcite we show that irreversibility and chaotic behavior in quantum mechanics corresponds to a complex pattern of entanglement that can not be undone by entanglement cooling . this pattern is revealed by wigner - dyson statistics in the entanglement level spacing statistics . <n> entanglement is a central concept in quantum information and computation .<n> it has been shown that entanglement can be used to solve problems in many areas of science and technology @xcite . in particular ,<n> quantum computation has been proposed as a powerful tool to solve some problems in physics and engineering , e.g. , fault - tolerant quantum computation , quantum error correction , and quantum metrology . however , in order to realize quantum computation efficiently , we need to understand the behavior of quantum systems in the presence of decoherence , which is a major problem in classical computation and quantum information theory . to this end<n> , there has been a lot of progress in the understanding of the dynamics of quantum many - body systems , especially in the realm of superconductivity , superfluidity , bose - einstein condensates ( becs ) , topological insulators , as well as in the field of strongly correlated electron systems ( pcs ) and superconductor we show that irreversibility and chaotic behavior in quantum mechanics corresponds to a complex pattern of entanglement that can not be undone by entanglement cooling . this pattern is revealed by wigner - dyson statistics in the entanglement level spacing statistics .<n> we speculate that signatures of this behavior may be found in higher moments of the entanglement entropy , since after all , knowledge of all the rnyi entropy should in principle allow to reconstruct the whole reduced density matrix spectrum . <n> quantum mechanics is one of the most studied areas in modern physics , with topics ranging from the foundations of quantum mechanics to the study of quantum information processing @xcite . in this paper<n> , we present a new way to characterize , through entanglement , quantum systems that do not thermalize , as breaking of thermalization must come from breaking of ergodicity . to do this ,<n> we first show that universal quantum computation always produces complex entanglement . on the other hand , non - universal quantum computing results in a breaking of gue theory , in turn ensuring that entanglement is not complex and easily undone , and this is revealed in poisson level spacing statistic , which in turn follows the gue prediction : @xmath0 where @x",
      "metrics": {
        "rougeL": 0.09535304767652385,
        "bertscore_f1": 0.841300904750824,
        "latency": 5.611498594284058
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 8,
      "doc_id": "dev_longform_711",
      "source_preview": "mechanical stimulation by toothbrushing is capable of inducing keratinization of the \n oral sulcular epithelium , enhance \n gingival circulation , cause \n formation of procollagen synthesis of gingival fibroblasts , and increase alveolar \n bone . \n in addition , it has been \n shown that proliferation of basal cells , fibroblasts and synthesis of procollagen i are \n promoted more effectively by mechanical stimulation with a toothbrush than by removal of \n dental plaque . \n conversely , a very int",
      "source_length": 26184,
      "reference": "periodontitis comprises a group of multifactorial diseases in which periodontopathogens accumulate in dental plaque and trigger host chronic inflammatory and immune responses against periodontal structures , which are determinant to the disease outcome . although unusual cases of non - inflammatory destructive periodontal disease ( nidpd ) are described , their pathogenesis remains unknown . a unique nidpd case was investigated by clinical , microbiological , immunological and genetic tools . the patient , a non - smoking dental surgeon with excessive oral hygiene practice , presented a generalized bone resorption and tooth mobility , but not gingival inflammation or occlusion problems . no hematological , immunological or endocrine alterations were found . no periodontopathogens ( a. actinomycetemcomitans , p. gingivalis , f. nucleatum and t. denticola ) or viruses ( hcmv , ebv-1 and hsv-1 ) were detected , along with levels of il-1 and tnf- in gcf compatible with healthy tissues . conversely alp , acp and rankl gcf levels were similar to diseased periodontal sites . genetic investigation demonstrated that the patient carried some snps , as well hla - dr4 ( * 0404 ) and hla - b27 alleles , considered risk factors for bone loss . then , a less vigorous and diminished frequency of toothbrushing was recommended to the patient , resulting in the arrest of alveolar bone loss , associated with the return of alp , acp and rankl in gcf to normality levels . in conclusion , the unusual case presented here is compatible with the previous description of nidpd , and the results that a possible combination of excessive force and frequency of mechanical stimulation with a potentially bone loss prone genotype could result in the alveolar bone loss seen in nidpd .",
      "generated": "in this paper , we report a unique case study of a non - inflammatory destructive disease ( nidpd ) in which mechanical stimulation resulted from daily oral hygiene was supposed to trigger alveolar bone loss .<n> however , in cases where probing penetration was not prominent and no apparent plaque formation or accumulation of gross calculus were observed , the patient presented no evident radiographic signs of the disease . we present a case study of a non - inflammatory destructive disease ( nidpd ) , a chronic inflammatory disease of the oral and connective tissues .<n> the patient was submitted to standard protocols for evaluation of hematological , immunological and endocrine markers . as expected due to the oral condition of the patient , no apparent plaque formation , accumulation of gross calculus or inflammation<n> were observed before the occlusion of healthy sites . additionally , the apparent generalized horizontal algorithm recession was also observed in the non -  inflammatory disease case . <n> the results are representative of quantification of both inflammatory cytokines and bone metabolism mediators in non - inflammation destructive disease . * _ keywords : _ * inflammatory diseases , non - destructive disease [ [ section ] ] * background : * metabolic disorders are characterized by high levels of cytokines and bone mediators in the patient s blood , which may lead to a proliferation of the invader s cells , resulting in cell division , multiplication , and/or division into cells of different types , leading to cell death . <n> * purpose : _ we study the genetic basis of inflammatory diseases by means of a comparative analysis of systemic and molecular markers for the expression of inflammatory cytokines , porphyis phosphatases and fusobacterium icola in the human salivary ducts .<n> _ * methods : + _ the genetic analysis was performed in a longitudinal manner by following the progression of the inflammatory diseases in the patients , collected from healthy and diseased sites respectively . in this study<n> , we focused on the role of the different molecular mediators in inflammatory diseases , as quantified by their expression in systemic metabolism markers , such as acp , ilnf , alp and rankl in the gum tissue and in the bone , respectively , in terms of expression coefficients , expression ratios , binding energies , specificity , sensitivity and specificity for the production of specific at 2- and 6-month radiographic evaluations , the presence of localized recessional swelling was stabilized .<n> five years of follow - up showed no progression in the horizontal alveolar bone and no probing of the bone attachment , when compared with the initial findings . at the moment , no further radiographic analysis is necessary . <n> [ firstpage ] immune system , innate immune system we investigated the genetic and immunological background of a special case of chronic periodontitis , in which the patient presented a satisfactory phenotype and no evidences of inflammatory activity were found at immunological investigation .<n> however , the patient showed an intensive oral hygiene care period and bone lesion , suggesting an elevated bone metabolism in the diseased sites . in this case<n> , we next inspected some single nucleotide polymorphisms ( snp ) that could characterize the putative susceptibility phenotype . <n> first , all the evaluated sites were compatible with those seen in clinically healthy tissues , and half of the investigated snps suggest the occurrence of risk alleles for bone loss . on the other hand ,<n> the polymorphic heterozygous of the tfb -509tgnp seems to be a greater risk for the development of the disease , as compared to the mmp1 - 1607 genotype , regarding the gc t allele . in this paper , we present the results of a cross - correlation analysis between the hla - drb1 locus and the phenotypes of non - inflammatory destructive disease , in order to investigate the connection between the development of the disease and the occurrence of risk alleles .<n> the analysis was carried out in brazilian subjects with no previous clinical evidence for the disease development , and for a patient with chronic bone loss and non - negligible resorption of fibroblasts from the bone , which was observed after 2-month of treatment . <n> [ [ section ] ] in the present study , the genetic status of a patient was determined by comparing the expression levels of hla and snp , with the aim of investigating the relationship between the characteristics of the two polymorphisms and the disease characteristics . in particular , a complete analysis was performed by cross - correlating the two hla loci with the patient s phenotypes , for a total of 10 polymorphisms ( snps ) , including 6 polymorphic heterozygous genotypes ( tgp ) and 3 polymorphic non - heterozygosity ( phg ) allele . for each snp ,<n> the expression level mechanotransduction of bone cells is an important factor in the pathogenesis of nidpd .<n> recent studies demonstrate that the force- and frequency- of toothbrushing can affect the activation and proliferation of fibroblasts in the environment , however , such studies were limited in epithelial cells and that different types of forces result in biological response including bone resorption . accordingly , a classic example of force - inducedbone resorption is the application of forces of distinct magnitude over fibroblast tissues . while further , it was supported by laboratorial analysis , which demonstrates that the levels of alp , the acp and rankl in gcf were also greatly reduced , reaching nearby the control levels . in this study , based on the treatment of a patient with previously recommended 2-month and recommended re - synthesis treatment , less vigorous and diminished frequency of the toothbrushing<n> was applied , resulting in a significant reduction of the bone loss progression . <n> [ [ section ] ] [ [ theorem]lemma [ theorem ] proposition [ theorem)corollary [ theorems]remark",
      "metrics": {
        "rougeL": 0.13688888888888887,
        "bertscore_f1": 0.825127899646759,
        "latency": 5.0758984088897705
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 9,
      "doc_id": "dev_longform_403",
      "source_preview": "eclipsing binary star systems ( ebs ) are our primary source of measurements of the properties of stars @xcite .\nthey are vital tracers of the physical processes which govern stellar structure and evolution @xcite . from time - series photometry and spectroscopy of an eb it is possible to measure the masses and radii of the two stars empirically , and to accuracies of better than 1% ( e.g. * ? ? ?\n* ; * ? ? ?\nthese numbers in turn give the surface gravity and mean density of the stars .\nif measu",
      "source_length": 18519,
      "reference": "we present _ kepler _ satellite photometry of kic10661783 , a short - period binary star system which shows total eclipses and multi - periodic @xmath0scuti pulsations . a frequency analysis of the eclipse - subtracted light curve reveals at least 68 frequencies of which 55 or more can be attributed to pulsation modes . the main limitation on this analysis is the frequency resolution within the 27-day short - cadence light curve . most of the variability signal lies in the frequency range 18 to 31 d@xmath1 , with amplitudes between 0.1 and 4 mmag . one harmonic term ( @xmath2 ) and a few combination frequencies ( @xmath3 ) have been detected . from a plot of the residuals versus orbital phase we assign the pulsations to the primary star in the system . the pulsations were removed from the short - cadence data and the light curve was modelled using the wilson - devinney code . we are unable to get a perfect fit due to the residual effects of pulsations and also to the treatment of reflection and reprocessing in the light curve model . a model where the secondary star fills its roche lobe is favoured , which means that kic10661783 can be classified as an oea system . further photometric and spectroscopic observations will allow the masses and radii of the two stars to be measured to high precision and hundreds of @xmath0scuti pulsation frequencies to be resolved . this could lead to unique constraints on theoretical models of @xmath0scuti stars , if the evolutionary history of kic10661783 can be accounted for . stars : binaries : eclipsing stars : fundamental parameters stars : oscillations stars : variables : delta scuti",
      "generated": "we present the analysis of _ kepler _ short - cadence and long - cadence photometry of the @xmath0scuti star kic10661783 , a detached eclipsing binary system .<n> the components of this system are shown to be a double - lined eclipsing binary with an orbital period of 30.5h and an eccentricity of 0.125 . using the 2mass magnitudes of the system and the infrared flux method , we measure the effective temperatures of the two stars to be t@xmath1k and t=7k , respectively , and the radii of the components to be 8.71 and 7.80@xcite . the high photometric precision of the data allows us to perform a detailed analysis of the pulsations , which are found to be dominated by non - radial mixed modes with a mean frequency of 12.38mhz and an overall amplitude of about 6hz . we have also identified the fundamental stellar parameters of the stars empirically and to accuracies of better than 1% using the asteroseismology technique . <n> [ firstpage ] stars : oscillations binaries : eclipsing techniques : photometric we report the first detection of @xmath0scuti pulsations in a star of known mass and radius , kic10661783 .<n> the star was found to be an eclipsing binary ( eb ) in kepler s field of view , with an orbital period of 10.44h and a projected semi - major axis of 0.08m@xmath1 . by fitting the light curve using the wilson - devinney code , we find that the primary star is radiative and has a convective atmosphere with effective temperatures of 6100k and 5800k , respectively . the secondary star is a close binary with a period of 12.15h and mass of 0.65m@ x 2 , and is therefore likely to be sub - giant . <n> [ firstpage ] binaries : eclipsing stars : oscillations techniques : photometric . we present the results of a photometric study of the eclipsing binary star system kic10661783 , using the wilson - devinney light curve code .<n> we find that residual pulsation effects are visible during the secondary eclipse , but are not present in the light curve of a detached system . <n> binaries : eclipsing stars : fundamental parameters techniques : photometric . we present _ kepler _ photometry of kic10661783 , a semi - detached eclipsing binary system which shows total eclipses and multi - periodic @xmath0scuti pulsations .<n> we then present superwasp observations of this system , which allow us to precisely measure the orbital period of the system . <n> [ firstpage ] binaries : eclipsing stars : fundamental parameters methods : data analysis we report the discovery of kic10661783 , a semi - detached oea ( oscillating algol ) star , using data from the _ kepler _ satellite .<n> this star is a high - amplitude @xmath0scuti pulsator with an orbital period of 15.9 d and a semimajor axis of 0.08 r@xmath1 . <n> [ firstpage ] stars : oscillations techniques : photometric binaries : spectroscopic we present _ kepler _ observations of the @xmath0scuti variable star kic10661783 .<n> the star is detected with high signal - to - noise ratio ( s / n@xmath1 ) , allowing us to perform a detailed analysis of the radial pulsation spectrum . in this paper<n> , we present the results of a detailed spectral analysis , including the determination of the physical parameters of the star , as derived from the analysis of its radial and nonradial oscillations . <n> @xcite kic 10661783 is an oea ( intermediate mass star ) with one of the richest , if not the most complex , radial _ rr _ and _ v _ light curves known . from the _<n> kepler_/ycam photometry of this star we have determined its effective temperature , surface gravity , and projected rotational velocity . using the photometry and the radial velocity data we have derived the following physical parameters : effective temperature@xcite , gravity@x , mass@x<n> . the surface gravity of this oea is very low , @xxmath2 ,",
      "metrics": {
        "rougeL": 0.17370892018779344,
        "bertscore_f1": 0.8551779985427856,
        "latency": 4.571841239929199
      },
      "selection_reason": "first_10"
    },
    {
      "sample_id": 21,
      "doc_id": "dev_longform_236",
      "source_preview": "in 1936 , alan m. turing gave an example of a well - founded ( and thus mathematically solvable ) problem which he showed to admit no computable solution .\nmore precisely he first introduced what is now called the turing machine ( ) as an idealization ( ` _ _ model _ _ ' ) of a digital computer and revealed it capable of solving a vast variety of practical problems like , for instance , answering whether a given integer is prime .\n[ defproblem ] a computational _ problem _ is a subset @xmath0 .\n",
      "source_length": 29335,
      "reference": "recent works have independently suggested that quantum mechanics might permit for procedures that transcend the power of turing machines as well as of ` standard ' quantum computers . these approaches rely on and indicate that quantum mechanics seems to support some infinite variant of classical parallel computing . we compare this new one with other attempts towards hypercomputation by separating 1 ) its principal computing capabilities from 2 ) realizability issues . the first are shown to coincide with recursive enumerability ; the second are considered in analogy to ` existence ' in mathematical logic . * keywords * : hypercomputation , quantum mechanics , recursion theory , infinite parallelism . + * pacs * ( 2003 ) : 03.67",
      "generated": "the well - known turing machine ( ) is a digital computer capable of solving a vast variety of practical problems like , for instance , answering whether a given integer is prime .<n> it was first introduced by alan m. turing in 1936 as an idealization (  _ _ model _ ' ) of a digitalcomputer and revealed its ability to solve a wide variety of problems . since then , many further sensible notions of computability have been proposed , among them herbrand - gdel , recursion theory , software verification , and the language  prolog . ''<n> however , it is known that , contrary to what was originally intended , this machine can not be decided algorithmically . in this paper<n> , we present a proof of turing s limitation by proving that it is possible to decide within finite time whether a certain subset @xmath0 of a given size can be reduced to a given subset , i.e. , whether @math1 can be made to stop . <n> * keywords : * hilbert s tenth problem , turing machines , herbrand gdel recursion , quantum computers , in this paper , we show that the halting problem can be solved by a quantum computer . <n> * keywords : * turing machine , halting problem , quantum computer hypercomputation , that is , the ability of a computer to process data faster than any other , is a subject of active research .<n> it is motivated by post s problem , i.e. , whether there might exist a computing device that solves the halting problem provably in finite time . <n> recently , several new approaches have been suggested for solving either the halting or the tenth problem . they exploit quantum mechanics and thus form a nice counterpart to previous approaches based on general relativity as the other pillar of non - classical physics . recalling that  standard ' quantum computing does not exceed turing s barrier , these approaches must be non - standard in some sense which closer inspection reveals to be infinite parallelism . in this paper<n> , we investigate such enhanced abstract models of computation and their respective computational powers by logicians and theoretical computer scientists . for example , [ 1 ] shows that there exists an entire hierarchy of undecidable problems strictly  easier ' than @xmath0 ; [ 2 ] indicates that a physical system breaking condition [ 3 ] might actually exist ; and [ 4 ] points out that [ 5 ] seems to be artificial . the present work shows how quantum mechanics allows to _ lift _ ord s classification and so to provide a new promising approach to the existence of hypercomputers .<n> the principal computing power of an _ infinite type of quantum parallelism _ is shown to be that of a _ countably infinite number of fock states_. we analyze the capabilities of an _ infinite _ number of parallel machines .<n> in particular , we show that they are provably more powerful than a single one . this paper introduces the notion of _ infinitely parallel computability _ : given a problem @xmath0 , a countably infinite family of s , each of them capable of computing , upon input of any number ,  1 '' , (  0 '' ) , if for each @xcite , and  2 '' if for any  3''-input , eventually terminates , then so does the problem .<n> we show that , in contrast to the well - known notion of infinite turing - parallelism , the above parallelism is provably more powerful than any finite number of automata . as a consequence ,<n> we prove that the halting problem and hilbert s tenth problem are solvable by an infinity of infinitely parallel s but _ not _ by turing parallelism . <n> [ theorem]acknowledgement [ theorem ]algorithm [ theorem][ theorem]axiom [ section ] any semi - decidable problem @xmath0 is solvable in the sense of definition [ defparallel](i - iv ) iff it can be solved by an infinity of s working in parallel .<n> more precisely , infinite turing - parallelism can solve as well hilbert s tenth problem but _ not _ , that is , the halting problem . in this sense , _<n> _ parallelism _ can solve _ any _ semi - decidable problem , not just the tenth , in the same way that _ linear _ speed - up lemma solves it . <n> [ thm]the halting problem is solved in the following sense : given a family of _ parallel _ functions @xcite , given a binary encoding of a pair of functions , and given a fixed number of inputs , ask whether the input of each function eventually terminates ; otherwise , output  1 '' and  0 '' . + in this paper , we consider the problem of hypercomputation , i.e. , how fast can one possibly _ generate _ from a given input , an encoding of recent and independent approaches due to kieu , calude , and pavlov to hypercomputation via quantum mechanics rely on some sort of infinite classical turing - parallelism .<n> we suggest to bring more clarity into this subject by considering algorithmic/ computational issues separately from physical ones . regarding the respective complicated intertwined quantum mechanical constructions , procedures , & analyses , we suggest , in particular , to : * do quantum mechanics allow for infinite classical parallelism ; and , if so , of what kind ? * what kinds of idealized infinite parallelism yield which principal computational power ; that is , does it and by how far exceed the fundamental capabilities of a ? section [ seccomputability ] has pointed out that in fact infinite _ classical _ ( i.e. , turing- ) parallelism is sufficient for solving both the halting problem as well as hilbert s tenth problem . this leaves open whether the infinite dimensions of quantum mechanical hilbert space do indeed allow for this kind of infiniteclassical parallelism , which is likely to raise here even more difficulties than already in the finite - dimensional case of  standard ' quantum computing . for example only recently has it become possible in this paper we address the question :  what is the physical limit of quantum computation ? '' in particular , in the finite - dimensional case of  standard ' quantum computing , what is its  physical limit ' ? and ,  can it be understood in terms of the complexity theory of computation '' ?<n> we show that the answer to the first question is in the negative . <n> turing computability is a fundamental limit of computation @xcite .<n> this is the minimum number of operations , required to carry out a computation , that can be performed on a given physical system . in the case of classical computation<n> , this number is given by @xmath0 , where the  number ' is defined as the probability of finding a solution to a given problem . for quantum computation ( qcc ) ,<n> the number is the number of qubits ( qudits ) required to perform a calculation , and this is known to be the maximum possible value . however in the presence of noise , one can not reach the maximum value of the number , since this value depends on the state of the qudit , as well as we show that the turing machine , i.e. the machine that can compute more than one number at a time , is not computable . <n> [ [ section ] ] in his famous paper , turing @xcite wrote :  it is not possible to decide whether a number is real or imaginary , and it is impossible to decide if it is a number or not . ''<n> his proof , based on recursion theory , has remained one of the most important unsolved problems in mathematics , despite the fact that it has been solved many times .<n> turing s problem was inspired by the work of gdel and others on the computability of numbers , which were concerned with the consistency of the axioms of choice and of the generalized continuum - hypothesis . in the 1940 s<n> , gdel raised the question whether general relativity allows an observer to see the past in a finite time . since then , a large number of papers have been written on the subject , including several papers by turing himself , many by matiyasevich , others by geroch , motwani , ullman , kieu , etc  turing s theorem states that for any @xmath0 , there is a one - to - one correspondence between the turing functions of two variables and the functions of the first variable . in this paper<n> we show that this correspondence extends to the case of a non - empty set .<n> in particular , we prove that if the set of turing - functions of a given variable is a subset of the ordinal of that variable , then the corresponding turing function of the second variable has the same form as that of the _ commutator _ of the two _ real _ variables . <n> turing theorem is one of the most important results of the last half - century , and its proof has been the main one in the field of recursion theory since the early days of quantum mechanics @xcite . for a general set of variables ,<n> there are at least two or more commutation relations , which can be written as follows : [ 1 ] [r ] n(x , y )  sum_n,endaligned ] where n is the number of non - negative integers ,",
      "metrics": {
        "rougeL": 0.050768203072812296,
        "bertscore_f1": 0.8155919313430786,
        "latency": 6.295290231704712
      },
      "selection_reason": "worst_rouge"
    },
    {
      "sample_id": 10,
      "doc_id": "dev_longform_641",
      "source_preview": "for @xmath0 centre - of - mass ( cm ) collision energies above the @xmath1 pole , @xmath10 , an important contribution to the cross section for @xmath11  jets comes from the so - called `` photonic returns to the @xmath1 '' , i.e events in which one or more photons are emitted by the colliding electron - positron beams prior to the annihilation of the latter into the virtual @xmath1 @xcite .\nsuch emission can carry away a large fraction of the collider energy , so that the amount left over for t",
      "source_length": 28769,
      "reference": "the production of four hadronic jets in @xmath0 collisions above the @xmath1 pole is dominated by the qcd @xmath2 processes and , for sufficiently high energy , the electroweak @xmath3 process . however there is another mechanism for producing four jets , @xmath4 , which can be regarded as a `` hadronic return '' to the @xmath1 pole . we investigate this new process in detail . 0 pt 42by .25 truein .25 truein 1 in 0.75 in 6.35 truein = 100000 # 1 # 2 # 3 _ phys . lett . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ nucl . phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ j. phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ z. phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ phys . rev . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ phys . rep . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ phys . rev . lett . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ mod . phys . lett . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ rev . mod . phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ sov . j. nucl . phys . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 _ comp . phys . commun . _ * # 1 * ( # 2 ) # 3 # 1 # 2 # 3 * # 1 * , ( # 2 ) # 3 ral - tr-98 - 036 + dtp/98/14 + june 1999 + * hadronic returns to the @xmath5 + in electron - positron annihilation at high energy * + v.a . khoze@xmath6 , d.j . miller@xmath7 , s. moretti@xmath8 and w.j . stirling@xmath9 + _ a ) department of physics , university of durham , _ + _ south road , durham dh1 3le , uk . _ + _ b ) infn laboratori nazionali di frascati , _ + _ p.o . box 13 , i-00044 frascati ( rome ) , italy . _ + _ c ) rutherford appleton laboratory , _ + _ chilton , didcot , oxon ox11 0qx , uk . _ + _ d ) department of mathematical sciences , university of durham , _ + _ south road , durham dh1 3le , uk . _ +",
      "generated": "hadronic  returns '' to the @xmath0 centre - of - mass collision energy in the vicinity of its peak may constitute a sizeable background at lep2 and/or a future linear collider .<n> such events are characterized by the emission of two energetic gluons in an internal quark - antiquark loop , allowing for a reduction of the collision energy to the order of a few gev / c@xmath2 . <n> cern - ph - th/2007 - 263 + desy 07 - 093 + hep - ph/0701271 + * hadronic returns to the * + * @xcite * the center of mass energy of a future electron - positron collider * + s.j . stirling , h. yamamoto + _ theory division , cern , ch-1211 geneva 23 , switzerland _ + and + t. gehrmann , w. majerotto +<n> _ institut fr theoretische teilchenphysik und kosmologie , + rwth aachen university , d-52056 aaschen , germany _<n> + we calculate the @xmath0 production cross section at one - loop order in the standard model with two massive quarks and two massless quarks in the final state .<n> the main motivation is the background from the decay of the first excited state of the @ x(3872 ) boson to an electron - positron pair , the so - called hadron resonance ( hr ) events . <n> we find that the cross section is strongly peaked at the mass of the low - mass peak of the process , which is of the order of the product of the two coupling constants , and also , if the kinematics allow , at the same value of the coupling constant . as a consequence ,<n> the hr events are a sizeable background for processes like @x , @xcite , ew , etc . when the decay products are degenerate , like for example in the case of the higgs boson decaying into a pair of jets at the lhc , there are hr events as well . in this case<n> the background is dominated by the double - gluon emission , with the jet mass distribution being invariant in the relative angle between the two gluon jets . at @ we study the process @xmath0 at high energies and in the small-@xmath1 limit .<n> we show that , contrary to previous claims , this process can not be described by using a fourth - rank tensor in the amplitude squared , as had been assumed in the literature . instead , we find that the amplitude is dominated by singularities in the determinant of the fourth - order tensor integral . <n> pacs numbers : 11.15.bt , 12.38.bx , 13.60.hb , 14.40.aq the problem of the origin of the mass of the higgs boson is one of the most important unsolved problems in high energy physics . in the standard model of particle physics ,<n> this is due to the fact that the electroweak symmetry is spontaneously broken by the interaction of the quarks and gluons with the photons of the vacuum . as a result<n> , there is a discrepancy between the predictions of the minimal supersymmetric standard model ( mssm ) and those of quantum electrodynamics ( qed ) , which are based on the su(3 ) symmetry of the gauge theory , for energies of the order of a few gev @xcite we present a detailed study of the hadronic returns to the top quark in @xmath0 collisions at lep2 and at the next linear collider ( nlc ) .<n> we show that the production cross section of the process , as a function of the center - of - mass ( cm ) energy , is strongly dependent on the relative size of the top and bottom quark propagators . at cm energies above the top - antitop threshold ,<n> the total cross section for the process is of the order of 0.012 fb , which is too small to be observed at the lhc . on the other hand , at nlc running at around 500 gev<n> , a handful of events will be produced at the end of the collider lifetime , well above the detection level . <n> the observation of top - quark ( tq ) pairs at the large hadron collider , i.e. lhc @xcite , will provide a crucial test of the standard model ( sm ) and of its extensions . in particular , it will be possible to determine the cp violation in the sm , to search for new physics effects , and we consider the production of higgs bosons in association with a photon in high energy @xmath0 collisions .<n> we show that such events are copiously produced at an nlc running at 500 gev , and that they can be used to test the electroweak standard model . in this context , we also discuss the possibility of observing higgs production via the @xcite mechanism . <n> it has been proposed some time ago that high energy photon - photon collisions could be used as probes of electroweak symmetry breaking in the context of the standard model ( sm ) . at the same time<n> , it is of interest to see if the sm predictions are robust enough to be tested at future colliders , such as the large hadron collider ( lhc ) and the next linear collider , or even the tevatron , which is currently under construction in the u.s . the interest in this subject goes back to the early days of the sm itself , when it was first pointed out that it was possible to solve the hierarchy problem of the quark gluon plasma ( qgp ) in a way that is compatible with the smallness of the masses of the we present the results of a calculation of the cross sections for the processes @xmath0 and _ on - shell _ _ bjorken - x at lep2 energies .<n> it is shown that the rates are well below detection level , but that the interference between the tree - level and the one - loop amplitudes could allow for a significant effect , at least at the order of the renormalisation scale . _<n> pacs : 12.38.-t , 13.60.hb , 13.85.lg _ keywords : _ jet production at hadron colliders , in particular lep and tevatron , has been the object of a lot of attention during the last few years . in this context<n> , it is important to understand what can be learned about the qcd dynamics from the measurements of the rates of these processes , and what constraints can be placed on the parameters of the theory ( such as the ckm matrix elements ) from these measurements . at present , however , there is no consensus on the determination of these parameters , even though a consensus has been reached in the community about the value of the scale @xcite . at lep2 hadronic returns , the interference effects of the four - jet contributions induced by the @xmath0 and higgs - boson self - energy diagrams are too small to be observed . on the other hand ,<n> the interference between the tree - level and loop - level contributions is sizeable , and would have serious implications for the higgs search . <n> lpt orsay 08 - 70 + pccf ri 08 - 08 + + * interference effects in the four- and two - jet production of a higgs boson at hadron colliders * + a.g .<n> de oliveira@xmath1 , g.p . martinez - mueller@xcite , m.g.<n> ryskin@x , a. vidiella - barranco@ xcite + _ _ we show that  hadronic returns ' to the @xmath0 final state , in which two gluons are emitted in association with a quark pair , constitute a novel source of two - lepton and four - jet events at a next linear collider ( nlc ) .<n> they are significant enough to be observed at such a collider , since their interference with the tree - level contribution to the total four - jets rate is negligible also at lep2 . <n> cern - ph - th/2007 - 074 + desy 07 - 099 + july 2007 * hadronic return processes to @xcite @x : * * in high - energy @ x - annihilation , we study the effects of what we have called hadronic returns ( hr ) '' to the@xmath1 . these correspond to diagrams in which a primary current originates a quarks loop from which two gauginos are emitted , the former being energetic enough so that the latter is near its mass - shell . in every channel studied ,<n> the contributions of the hr processes are completely negligible . however , at an nlc with energy between 350 and 500 gev , they can we calculate the high - energy ( hr ) contributions to the @xmath0 production cross - section due to the kuraev - fadin mechanism .<n> they are significant enough for an nlc with energy between 350 and 500 gev to be of interest . <n> dtp/97/70 + june 1997 + 1.cm * high energy contributions * 1.cm t. gehrmann and w.j . stirling .4 cm _ department of physics , university of durham + durham dh1 3le , england _ <n> 3.cm pacs numbers : 13.60.hb , 13.85.ni , 14.40.nd 16.cm 22.cm @=11 tempcntc citex[#1]#2@fileswauxout tempcnta@tempcntb@neciteaciteforciteb:=#2citeo#1 citeotempcnta > tempcnt b @=12 <n> = cmssbx10 scaled 2 to we present a model for the production of @xmath0 in association with a jet .<n> we assume that the jet is produced in hadron - hadron collisions at hera and consists of a jet of longitudinally polarized partons and a longitudinally unpolarized parton scattered off the parton which decays to the hadron . in this model ,<n> the transverse momentum of the jet as a function of the hadronic transverse momentum is determined by the transverse size of the partonic parton , which in turn depends on the transverse profile of the hard scattering partons . <n> = cmr8 1.5pt # 1#2#3#4#1 * # 2 * , # 3 ( # 4 ) the study of jet production at hadron colliders ( hera , lep and tevatron ) has been one of the main topics in the field of high energy qcd since the early days of qcd @xcite . the main motivation for this study is the search for signals of new physics beyond the standard model ( sm ) , in particular signals of the chiral symmetry breaking ( csb ) in the qcd sector of the theory . at high transverse momentum ( @x",
      "metrics": {
        "rougeL": 0.06047516198704104,
        "bertscore_f1": 0.7853261828422546,
        "latency": 6.064486742019653
      },
      "selection_reason": "worst_rouge"
    },
    {
      "sample_id": 20,
      "doc_id": "dev_longform_512",
      "source_preview": "the winds of o and wr stars couple high mass - loss rates of @xmath1 to a few times @xmath2 with fast velocities typically @xmath3 .\nthe ram pressure balance between the hypersonic winds determines the position of the wind - wind collision region ( wcr ) .\nshocks are formed either side of the wcr which thermalize the plasma , heating it to @xmath4k .\nthe properties ( e.g. density ) of the wcr can span a very large range ( see e.g. table  2 in * ? ? ?\n* ) , reflecting the diversity of the underly",
      "source_length": 25009,
      "reference": "the powerful wind - wind collision in massive star binaries creates a region of high temperature plasma and accelerates particles to relativistic energies . i briefly summarize the hydrodynamics of the wind - wind interaction and the observational evidence , including recent @xmath0-ray detections , of non - thermal emission from such systems . i then discuss existing models of the non - thermal emission and their application to date , before concluding with some future prospects .",
      "generated": "the winds of o and wr stars couple high mass - loss rate and hypersonic velocities .<n> the ram pressure balance between the hypersonic winds determines the position of the wind - wind collision region ( wcr ) . shocks are formed either side of the wcr which thermalize the plasma , heating it to @xmath0k . particle acceleration at the shocks<n> is likely to occur in wider systems , particularly since the changing separation of the stars is useful as a probe of the physics which takes place . colliding wind binaries ( cwbs )<n> are also useful as simpler , less complicated , analogues of the multiple wind -wind collisions which occur throughout the volume of clusters of massive stars . here<n> we review the current status of the hydrodynamical modelling of the winds in colliding wind systems . wr 147 is one of the best studied of the well - known wr+o binaries , and has been the subject of a long - term study by @xcite .<n> this system displays a remarkably wide ( @xmath0au ) , non - thermal radio continuum , which is likely to arise in the adiabatic , dense wind of the o star . however , the lack of success in this undertaking appears to show that the physical conditions necessary to produce _ observable _ emission at radio and hard x - ray energies are mutually incompatible . in just the last few months<n> , definitive evidence for non - thermally emitting particles in wr147 has finally been presented in recent years , with an especially exciting period in only the last couple of months . here , i present new , high spatial resolution , very long baseline interferometry ( vlbi ) observations of the system , showing that , despite the wide range in separation between the stars , there is still a clear , coherent pattern in the structure of the wcr . <n> [ 1996/06/01 ] 2@xmath1 2c ii 4c iv 2fe ii 3fe iii we review the current status of the modelling of the non - thermal radio and @xmath0-ray emission from cataclysmic variables ( cwbs ) , with particular emphasis on the role of the low - opacity , hot , low - density circumstellar wind ( wcr ) in the acceleration of the acceleration particles .<n> we show that the presence of the wcr is crucial in determining the observed properties of the emission , in particular , the spectral index of the synchrotron - self - compton ( ssc ) emission . for a given set of physical parameters ( e.g. the mass of the central star , and the distance between the star and the observer )<n> , we find that the observed spectral index is very sensitive to the value of the stellar mass , while the value is much less so for the distance . as a result ,<n> the observed values of the spectral indices are very sensitive not only to the effective temperature of the emitting electrons , but also to the electron density and to the magnetic field strength in the w cr . <n> we also discuss the role played by the o - star s wind in the radiative transfer process . in this case  we review the models of the thermal and non - thermal radio emission from colliding wind binaries ( cwbs ) , and their predictions for the @xmath0-ray emission from these systems .<n> we describe the basic assumptions of the models , as well as some of the problems and uncertainties that have arisen since these models were first presented in the early 1990 s . <n> we then discuss the latest developments in our understanding of the @ x - ray emission from cwb systems , with particular emphasis on the _ direct _ detection of the x - rays from the colliding wind binary , sgr a * , using _<n> chandra _ and _ xmm - newton_.<n> this source was recently found to exhibit a large , single - peaked , double - lobed x -ray profile , suggesting that it is a cwb , rather than a supernova remnant , in which case we would expect to see a much larger x - - ray luminosity from this source . finally , we discuss the prospects for future detections of the synchrotron emission from the wcr , which is thought to be responsible for a large fraction of the total synchrotron luminosity in these systems we review the models of the x - ray and @xmath0-ray emission from colliding wind binaries , and their implications for the interpretation of observations .<n> in particular , we focus on the ic emission from wr140 , which is expected to be detectable with glast / fermi , as well as on wr20a , a wr+wr binary , for which no firm conclusions can be drawn at present from the available data . <n> [ firstpage ] x - rays : binaries stars : winds , outflows radiation mechanisms : non - thermal . in recent years there has been a steady improvement in theoretical model predictions of the non - thermal emission from cwbs , in both the radio and @xmath0-ray domains . in this talk ,<n> i will review some of the recent work , and discuss future work which is being driven by corresponding advances in the observational front . in this talk , i will review some of the recent advances in modelling non - thermal emission from active galactic nuclei ( agn ) , with particular emphasis on the effects of particle acceleration on the underlying thermal plasma . <n> [ 1999/12/01 v1.4c il nuovo cimento ] we report on the detection of gravitational waves ( gws ) from the earth - moon - like dwarf novae ( dm - dgw ) that were ejected in the geomagnetic field .<n> the observations were carried out by the all sky monitor ( asm ) on board the _ hubble space telescope _ ( _ hst _ ) , using the wide field camera 3 ( wfc3 ) and the green bank telescope ( gbt ) in the energy range from 4 kev to 40 kev . <n> the gw signal was detected in the frequency range from 0.1 hz to 10 hz , with a detection rate of @xmath0 for the highest frequency signal ( @xcite , see also ref . and references therein )<n> . the signal was linearly detected up to a maximum frequency of 10 ghz , at which point it steepens to a quadratic power - law form . in the high frequency range ,<n> the amplitude of the gravitational wave signal is higher than that of the background , which is due to the fact that the source has a higher density than the background in the field of view of the asm - gb we report on the observation of x - ray emission from the binary pulsars psr j0737 + 6736 and psrs j1327 + 6716 , which have a spin - orbit coupling of @xmath0 .<n> x - rays were detected with a synchrotron radiation source at an average energy of 22 mev , with a corresponding energy loss rate ( edr ) of 10@xmath1 erg s@xcite . in both pulsars ,<n> the spin of the central black hole ( bh ) is aligned with the orbital angular momentum of the binary system , while the spins of the other pulsars are perpendicular to the orbital axis . for the pulsars with spin - orbital coupling ( soc ) , the spin - down of the pulsar , due to the interaction with the surrounding medium , leads to the formation of a spin density wave ( sdw ) in the pulsar magnetosphere . <n> recently , several experiments have been carried out to study the spin dynamics of binary pulsar systems with roche - lobe overflow ( rlof ) and/or pulsar magnetization ( pm ) @xcite<n> . the spin",
      "metrics": {
        "rougeL": 0.06084867894315452,
        "bertscore_f1": 0.8285835981369019,
        "latency": 5.613659381866455
      },
      "selection_reason": "worst_rouge"
    },
    {
      "sample_id": 26,
      "doc_id": "dev_longform_380",
      "source_preview": "although there have been advancements in the treatment of diabetes in recent years , diabetic retinopathy ( dr ) remains the most common cause of blindness among adults . according to the wisconsin epidemiologic study of diabetic retinopathy ( wesdr ) , 3.6% of type 1 diabetes patients and 1.6% of type 2 \n diabetes patients were legally blind.1 the time of disease onset is evident in type 1 diabetes patients , therefore we know with certainty that the development of dr is unusual before the fift",
      "source_length": 24896,
      "reference": "there has been a considerable advancement in the treatment of diabetes and understanding of the biochemical mechanisms underlying diabetic complications in the last 20 years . however , this advancement has not translated into a consistent reduction in diabetic retinopathy , one of the most frightening complications of diabetes mellitus . it is probable that greater attention to preventive intervention will help reduce the damage load in the next future , and that several drugs for the treatment of more advanced stages of diabetic retinopathy will become available . competent strategies targeting prevention based on screening programs should be proposed to reduce the burden and to improve the clinical outcome of this devastating diabetes complication .",
      "generated": "the development of diabetic retinopathy is unusual before the fifth year of the disease onset and reaches a prevalence of more than 95% 15 years after disease onset . on the contrary , up to 20% of type 2 diabetes mellitus patients<n> may have signs of retinopathy at the time of diagnosis , which is rich in cones that are critical for color and daytime vision .<n> this study mainly reviews prevention in the initial stages of the diseases when medical intervention may be effective . the progression of the disease is controlled by various mechanisms , including hyperglycemia , type 2 diabetes , high cholesterol , and high blood pressure .<n> the exact mechanisms are unknown , but we still do not know the exact influence of each on the different stages of the diseases . in the initial stages , blood vessels in the retina are severely damaged , which leads to the formation of small blood vessels ( capillaries ) in the central and peripheral regions of the retina , called cones , that are critical for color and daytime vision . <n> the disease progresses to full hemodynamics of the vitreous material in the macula , leading to complete occlusion of the macula and complete loss of the vision.1 in 5@xmath0 of the population develop type 1 diabetes . by type 2<n> diabetes irreversible damage of the retinal tissue occurs due to the action of the sugars in the insulin process .2 in 10% of the diabetes patients will develop diabetes completely .3 in 10% have type 1 disease .4 in 15% have type 2 disease but show no signs of retinopathy.5 in 10% develop retinopathy but show clear evidence of it .6 in 15% develop csdme , a complication that is believed to [ [ background ] ] background : + + + _ purpose : _ the dcct was designed to study the effect of intensive glucose control on the progression of proliferative disease in newly diagnosed type 2 diabetes .<n> the protocol was random , i.e. , each patient was assigned to an intensive or conventional treatment group , and the risk of microvascular complications was determined by the blood glucose level . <n> [ [ methods ]<n> ] methods : = _ monte carlo _<n> algorithm was used to estimate the percentage of subjects whose blood glucose levels were below a given threshold . in the protocol , the threshold was determined based on the areas under the receiver operating characteristic curves . [ [ results ] * * results from dcct : * in a population of individuals over the age of 18 years , a statistically significant ( @xmath0 ) reduction in the relative risk of retinopathy was found , with a median of 24% reduction in microvascular complication . this result was based on a random assignment of 3867 newly diagnosed individuals to an intense or conventional therapy . *<n> * results _ * * from ukpds : the effect on the risk the primary cause of death from diabetes is characterized by an excess of blood glucose ( glucose ) .<n> this excess , known as diabetes , leads to damage in endothelial cells at the mitochondria level , which in turn causes dna damage , and the consequent attempt to repair the damage starts the aforementioned dangerous cascades involved in the pathogenesis of dr.@xmath0 one of the most important and still not totally explored aspect is that oxygen - free radicals can activate nuclear factor b and in turn many genes related to vascular stress response . <n> the mechanisms of damage are still not completely understood , although the literature on the pathogenetic mechanisms that lead to dr is abundant , exploiting the mechanisms did not yield fruitful results . control of hyperglycemia proved to be the mainstay of prevention of dr and progression of the disease was able to be reversed to a certain point . in the intensive treatment of diabetes<n> , the physicians should make a causal treatment for dr . an increase in vegf in the retina<n> leads to loss of pericytes , causing blood retinal barrier dysfunction , increasing synthesis of vegf and increasing monocyte adhesion to the retinal endothelial cells through an increase of the expression of intercellular adhesion molecule 1.43 amino * abstract * :vascular endothelial growth factor ( veg ) plays an important role in the growth of the blood vessels in the retina . in dr ,<n> the veg mediates blood flow to and from the vitreous vessels , which is essential for proper translation of nutrients into blood .<n> however , veg is not the only mechanism of blood flow in the eye , where it is involved in the formation of osmotic vessels . <n> angiogenic growth factors , such as growth hormone ( gh ) and insulin - like growth factor-1 ( igf - i ) , may also contribute to the development of proliferative diabetic retinopathy ( dr ) in addition to the more common proliferative schwinger - kelvin ( prg ) schwinger retinopathy ( pfdr ) that leads to proliferative vitrification of the vitreous tissue in dr.65 in the presence of high blood glucose , it is expected that the blood glucose level will increase in turn , leading to further damage to the vitreous structure and eventually to complete vitreous detachment from the retina.55 the results of the gh analogue , pegvisomant , have been used to induce regression of neovascularization  the aim of this review is to summarize the current status of pharmacological treatment of type 2 diabetes ( dr ) .<n> the review is divided into three parts : 1 . <n> treatment and prognosis of dr . in the first part ,<n> recent advances in the treatment of dr have been made , in particular , blood glucose control , laser treatment , and intervention in growth of neovessels and in vitrogenesis.2 . the second part of the review , which is devoted to prognostic aspects of the disease progression , includes the following observations : (1 ) in recent years , new drugs have been developed to control the progression of diabetes . however , the effectiveness of these drugs is limited , as demonstrated by the results of recent studies.(3 ) the effects of these new drugs are independent of lipid levels .4 <n> (2 ) some of the effective treatments of dr now involve surgical or laser procedures . finally , 3 ) recent progress in the understanding of the mechanisms of blood flow in the retina , including the observation of direct effects not mediated by angiotensin receptor blockers.4 in the conclusion of the third part of our review in this paper , we review the current status of the subdivided studies of the progression of choroidal and central lineal vasculability in primary and secondary proliferative eye diseases .<n> we also discuss the possible roles of the vasculature in the disease progression . <n> _ _ key words : _ retinal disease , primary ; secondary ; vasculopathic eye disease ;proliferative eye disease. _<n> pacs number(s ) : 05.50.+q , 05.40.+j , 87.16.yc , 68.18.jk _ contribution to the proceedings of the retinopathy 2010 conference , held in santorini , italy , may 30 - june 1 , 2010 . in this review ,<n> we focus on the subdivided study of primary phasic eye disease ( bppd ) in primary , secondary , and necrotic eye diseases ( nphd , pdph , npdh , ndh and amdph)@xcite . the characterization of the disease is based on the measurement of the eye s visual , auditory , olfactory , autonomic ,",
      "metrics": {
        "rougeL": 0.06841686555290373,
        "bertscore_f1": 0.8188368082046509,
        "latency": 4.918014764785767
      },
      "selection_reason": "worst_rouge"
    },
    {
      "sample_id": 16,
      "doc_id": "dev_longform_92",
      "source_preview": "Fox has decided to ditch its untitled Patricia Hearst biopic after she denounced the project. \n \n Twentieth Century Fox Film and its production partners have decided to cancel the studios planned project based on the book American Heiress,' a spokesperson for the studio said. \n \n The move came a few hours after Hearst had issued a strong denunciation of both the Fox movie biopic and a CNN documentary series about her 1974 kidnapping. She blasted author Jeffrey Toobin, whose unauthorized 2016",
      "source_length": 17058,
      "reference": " Twentieth Century Fox has canned a movie about Patty Hearst's 1974 kidnapping after she accused it of \"romanticizing my rape and torture.\" In a Thursday statement, Hearst said the film based on Jeffrey Toobin's 2016 biography of her, including details of her kidnapping and indoctrination into the anti-government terrorist group known as the Symbionese Liberation Army, was \"attempting to rewrite history,\" per the Washington Post. It \"directly flies in the face of the present #MeToo movement where so much progress is being made in regard to listening, and providing a voice, to those who have suffered abuse,\" added Hearst, granddaughter of the late media mogul William Randolph Hearst. She called Toobin's book \"a one-sided dialogue\" that \"cites one of my kidnappers as its main source\" and \"calls my abduction a 'rollicking adventure,'\" per Deadline. In reality, it's a story of \"a child having been destroyed both inside and out,\" said Hearst. Now 63, she was just 19 when she was kidnapped by the SLA on Feb. 4, 1974. She was arrested for bank robbery alongside group members a year and a half later but argued she'd been indoctrinated under threat of violence. She spent 22 months in prison before her seven-year sentence was commuted by President Jimmy Carter. Hearst, who was later pardoned, said Thursday that the Fox project would \"make me a victim again,\" reports People. Later Thursday, Fox said it was canceling the planned film, though it did not give a reason, reports Variety. A six-part CNN documentary on the case produced by Toobin will apparently air as planned on Feb. 11. Toobin will also co-host a weekly companion podcast with CNN's Brian Stelter beginning Jan. 26.",
      "generated": "in a recent letter to the editor of _ nucl . <n> phys .<n> _ , the author raised the following question : is it true that the law of limited supply of copies of a book by a single author is equivalent to that of a limited number of authors who share the same property ? in the following , i would like to express my deepest gratitude to my family , especially my mother , who has suffered so much in my life , and to my children , including my own . it is well known that the law of large numbers does not allow for the possibility of arbitrarily large numbers .<n> it is also well known , however , that a large number can be arbitrarily small , and that a small number can not be arbitrarily large . <n> [ [ section ] ] in this paper , we consider the following question : is it true that the following statement holds : [ 1 ] the following follows from the first law :  _ there exists a group in the world that has arbitrarily large number of constituents . '' _ [ 2 ] for each such group , there is a group of individuals , each of which is a constituent of the other groups . in other words , for each of these groups , the following statements hold : the following are the laws of large number : ( 1 ) _ the number of constituent members of a group is equal to the total number of members of the group ; _ ( 2 ) the following inequality is satisfied by the following set of inequalities : * [ 3 ] * the following inequalities are violated in the following way : @xmath0 for each member of a large group  in this short note , we address the following question : given that @xmath0 is the number of constituents in @xcite , does the number one defect of the original version of ?<n> the answer is : no .<n> there is no defect in the first version of the code . in the second version , there is a defect . we consider the case of a woman who was consensually held against her will by a number of men .",
      "metrics": {
        "rougeL": 0.12540192926045016,
        "bertscore_f1": 0.7743384838104248,
        "latency": 4.293811082839966
      },
      "selection_reason": "worst_bertscore"
    },
    {
      "sample_id": 40,
      "doc_id": "dev_longform_49",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Immigration Law Enforcement Act of \n1993''.\n\n   TITLE I--BORDER PERSONNEL, TRAINING AND INFRASTRUCTURE ENHANCEMENT\n\nSEC. 101. SHORT TITLE.\n\n    This title may be cited as the ``Improved Border Control and \nNarcotics Abatement Act''.\n\nSEC. 102. EXPANDED BORDER PATROL AND SOUTHWESTERN REGION DEPLOYMENT.\n\n    (a) Increased Personnel.--The Attorney General, in each of the \nfiscal years 1995 and 1996, shall increase by no fewer than 700 the ",
      "source_length": 16602,
      "reference": "TABLE OF CONTENTS: Title I: Border Personnel, Training and Infrastructure Enhancement Title II: Asylum Reform Title III: Criminal Alien Deportation and Enhanced Prisoner Transfer Immigration Law Enforcement Act of 1993 - Title I: Border Personnel, Training and Infrastructure Enhancement - Improved Border Control and Narcotics Abatement Act - Authorizes appropriations and increases personnel levels for: (1) the Border Patrol; and (2) land border inspectors. Provides for: (1) primary deployment of such personnel on the Southwest border of the United States; (2) hiring preference for bilingual Border Patrol agents; and (3) improved training and improvement of border crossing infrastructure. Authorizes appropriations for Immigration and Naturalization Service technology and equipment acquisition. Establishes in the Treasury the Immigration Law Enforcement Fund. Creates a border crossing user fee. Title II: Asylum Reform - Executive Order Enhanced Consideration Revocation Act - Amends a specified Executive Order to partially revoke a provision with respect to asylum claims based upon birth control policies. Title III: Criminal Alien Deportation and Enhanced Prisoner Transfer - Criminal Alien Deportation and Enhanced Transfer Act of 1993 - Amends Federal criminal law to provide for a judicial order of deportation in the sentencing of an alien convicted of certain aggravated felonies. Authorizes the Secretary of State with the Attorney General to negotiate agreements with foreign countries for home-country incarceration of aliens subject to U.S. deportation. Authorizes appropriations. Amends the Immigration and Nationality Act to: (1) make an alien convicted of an aggravated felony ineligible for suspension of deportation and status of adjustment; and (2) prohibit the waiver of exclusion for an alien convicted of an aggravated felony.",
      "generated": "we report the results of a study of the influence of the thickness of a channel on the performance of a high speed bridge .<n> we find that a channel with thickness of at least three times the width of the channel has better performance than a channel of the same thickness but with thickness less than twice the width . <n> high speed bridges , or hsbs , were first constructed in the 1960s to improve the transport of hazardous materials @xcite . during the last decade<n> , they have been used to improve transport in a variety of applications , such as earthquake prediction @xmath0 , chemical and biological control @x , earthquake prediction of materials , and prevention of landslides . in the early 1990s , a group of scientists at the university of california , berkeley ,<n> submitted a proposal to construct a hsb with a thickness of about three times its width , based on the idea of using a dispersive barrier to confine an object moving at a constant speed . a few years later , the berkeley group published a feasibility study of such a structure @x<n> . the feasibility study showed that a high density of dispersively confined objects could be achieved , with this is an answer to the question of whether the cost of enforcing international borders is proportional to the number of individuals detected at the border .<n> the answer is found in the following form : * * the following question is posed . * the price of enforcing ( international ) borders is related to the following two facts : ( i ) * the total number of persons detected at a border is determined by the total amount of narcotics detected at that border , and ( ii ) the amount of drugs detected depends on the type of the individual . for each such individual , there is a threshold number , below which there is no effective operation . in other words , for each person with a detectable quantity of narcotics , the price to enforce the international border is equal to the quantity of that person s narcotics . we consider the following question : under what conditions can an individual be considered to be a foreign national ? <n> the answer to this question is : the following .<n> a ) there is no _ a priori _ , in any court of law in the united states of america , whether or not an individual has been or is currently a citizen of the usa , of any other country in the union , or of any foreign country in which the individual has resided for a period of time in _ at least _ ten years . '' b ) the following statement is true . <n> : there is not any restriction on the number of years that an individual can be a citizen or a permanent resident of the u.s . under the following conditions : ( i ) for an individual who has been and is currently an alien , there are no restrictions on the amount of money that can be spent on his / her sustenance , nor on the type of property that he / she can possess ; ( ii ) no such restriction can be placed on the location of an individual ; and ( iii ) an individual is not prohibited from residing in any country we show that a recent claim in a local court concerning an alleged violation of the second law of thermodynamics is erroneous .<n> the claim is based on a misunderstanding of a fundamental difference between the fundamental laws of nature and of science .",
      "metrics": {
        "rougeL": 0.12150668286755772,
        "bertscore_f1": 0.7765806913375854,
        "latency": 4.435165166854858
      },
      "selection_reason": "worst_bertscore"
    },
    {
      "sample_id": 35,
      "doc_id": "dev_longform_355",
      "source_preview": "SECTION 1. SHORT TITLE; TABLE OF CONTENTS.\n\n    (a) Short Title.--This Act may be cited as the ``Temporary Tax \nHoliday and Government Reduction Act''.\n    (b) Table of Contents.--The table of contents of this Act is as \nfollows:\n\nSec. 1. Short title; table of contents.\n                      TITLE I--PAYROLL TAX RELIEF\n\nSec. 101. Extension of payroll tax holiday.\n                      TITLE II--DEFICIT REDUCTION\n\n        Subtitle A--Reform of Federal Benefits for Millionaires\n\nSec. 201. Ending u",
      "source_length": 17140,
      "reference": "Temporary Tax Holiday and Government Reduction Act - Amends the Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act of 2010 to extend through 2012 the 2% reduction in employment and self-employment tax rates. Amends the Internal Revenue Code to impose a 100% tax on excess unemployment compensation, as defined by this Act, received by certain high-income taxpayers. Amends the Food and Nutrition Act of 2008 to render ineligible for the supplemental nutrition assistance program (SNAP), formerly food stamps, any household in which a member receives income or assets with a fair market value of at least $1 million. Amends title XVIII (Medicare) of the Social Security Act to: (1) increase Medicare Part B and D premiums for Medicare beneficiaries with adjusted gross incomes over $750,000, and (2) extend through 2022 the freeze on the inflation adjustment to the income threshold for the Medicare premium subsidy eligibility. Requires the Director of the Office of Management and Budget (OMB) and the Director of the Office of Personnel Management (OPM) to determine the number of full-time employees employed in each federal agency. Prohibits a head of a federal agency from hiring more than 1 employee for every 3 full-time employees who leave employment in such agency until OMB and OPM make a determination that the number of full-time federal employees is 10% less than the initial level determined by OMB and OPM. Extends the freeze on the pay of federal employees through 2015. Provides that such extended pay freeze applies to legislative branch employees, including Members of Congress. Amends the Balanced Budget and Emergency Deficit Control Act of 1985 to reduce levels of discretionary spending for FY2013-FY2021. Buffett Rule Act of 2011 - Amends the Internal Revenue Code to allow taxpayers to donate an amount (not less than $1), in addition to any tax owed, which shall be deposited in the general fund of the Treasury and transferred to an account used to reduce the public debt.",
      "generated": "we address the question as to whether there is a relationship between the amount of compensation received by an individual and its membership in an association .<n> we show that the answer is negative . <n> * keywords : * association , income , unemployment . this is an appeal to the supreme court of the united kingdom for the reversal of the lower bound on the value of an asset .<n> it is shown that this lower bound is inconsistent with the natural law of conservation of energy , and is therefore invalid . <n> [ [ section ] ] let @xmath0 be the rate of decrease of the price of a commodity . in this case , <n> bariii(a ) rangle$ ] is defined in the following way : i ) the coefficient of the relation between the mean value of the asset and the price at which it is sold . for illustration , consider the case of a single asset , say the brown dwarf , whose value is equal to the square root of its price at the time of sale , multiplied by the square - root of the volatility of the market price at that time . [ [ thm]lemma ] [ [ theorem]corollary [ theorem ] proposition [ [ 1][proof]*#1 . * we address the question of whether there is a conflict of interest in the definition of a public official s wage and benefit .<n> specifically , we prove that there is no conflict of interests when the following two statements are true : ( i ) the law of the united states of america states that any individual who is employed by an agency which is funded by the national defense budget and whose functions are performed by that agency are described by its rules and regulations ; and ( ii ) for any such individual , there is an estimate of the amount of money he or she should be paid each year in order to maintain her / his employment with the agency . <n> [ [ section ] ] in section 1 , the following statement is stated : ] for any individual ( a ) who is an employee of an agency , is it true that the minimum wage he / she needs to be paid is equal to the sum of the square root of his or her annual fringe benefit and the cost of his / her hiring with the office of the controller of the account of the defense budget for that year . in section 2 ,<n> the statement is corrected , and the minimum amount of fringe benefit is calculated to be equal we consider the following question : what is the maximum amount of donation that can be made to a foreign body in the form of a tax that is due only to that body and is not due to any other entity ?<n> the answer to this question depends on the definition of the category of donation .<n> for example , it is defined as follows : (i ) for the purpose of donating to a country which is not a union of more than two countries , two of which are located in the same country , and whose population is at least three times denser than the population of the other country . <n> ii ) we define  ( iii ) the maximum value of the tax due to the country in which the donation is made . for a person residing in the united states of america ,<n> the maximum donation is equal to @xmath0$ ] , while for a resident of the state of new york state , the maximum is of the order of $ 10  leq 3  5  $ ] ( where the definition is 3omega[omega]2] ) iii )",
      "metrics": {
        "rougeL": 0.1592920353982301,
        "bertscore_f1": 0.7767207622528076,
        "latency": 4.486410617828369
      },
      "selection_reason": "worst_bertscore"
    },
    {
      "sample_id": 19,
      "doc_id": "dev_longform_404",
      "source_preview": "SECTION 1. SHORT TITLE.\n\n    This Act may be cited as the ``Social Security Number Protection \nAct of 2005''.\n\nSEC. 2. FINDINGS.\n\n    The Congress makes the following findings:\n            (1) The inappropriate sale or purchase of Social Security \n        numbers is a significant factor in a growing range of illegal \n        activities, including fraud, identity theft, and, in some \n        cases, stalking and other violent crimes.\n            (2) While financial institutions, health care provid",
      "source_length": 15403,
      "reference": "Social Security Number Protection Act of 2006 - Amends title II (Old Age, Survivors and Disability Insurance) of the Social Security Act (SSA) to make it unlawful for any person to sell or purchase a Social Security number in a manner that violates a regulation promulgated by the Federal Trade Commission (FTC). Directs the FTC to promulgate regulations restricting the sale and purchase of such numbers and any unfair or deceptive acts or practices involved in such a sale or purchase. Requires such regulations to be no broader than necessary to: (1) provide reasonable assurance that Social Security numbers will not be used to commit or facilitate fraud, deception, or crime; and (2) prevent an undue risk of bodily, emotional, or financial harm to individuals. Requires such regulations also to include exceptions which permit the sale and purchase of Social Security numbers to the extent necessary for: (1) law enforcement, national security, and public health purposes; (2) research conducted for the purpose of advancing public knowledge, subject to certain conditions; and (3) legitimate consumer credit verification, if the numbers used are redacted in accordance with uniform redaction standards established by the FTC in such regulations. Requires exceptions also for the sale and purchase of such numbers to the extent: (1) necessary in emergency situations to protect the health or safety of one or more individuals; and (2) consistent with an individual's voluntary and affirmative written consent to the sale or purchase of his or her number. Prescribes enforcement requirements. Authorizes states to bring civil actions on behalf of state residents in a U.S. district court to: (1) enjoin an act or practice; (2) enforce compliance with the regulation; (3) obtain civil penalties in an amount of $11,000 per violation, up to a total of $5 million; or (4) obtain other appropriate legal and equitable relief. Allows the U.S. Attorney General to institute a criminal proceeding for a violation of this Act.",
      "generated": "we address the following question : is there a restriction on the numbers that can be used in a financial transaction ?<n> specifically , we show that the number may not be used as a proxy for the identity of an individual , or for the number of an application , nor does it suffice to consider the number to be the same for each application . <n> our main result is that : a ) there is no _ a priori _ restriction on numbers .<n> b ) the numbers may be used for an application only if they are the same as the numbers used in the application ; and c ) for an individual to have a number , they must have a valid financial account . '' [ [ section ] ] in recent years , there has been a growing interest in the number - theoretic issues . in particular ,<n> the number theory has been the object of considerable recent attention , partly because of its connection to financial markets , and partly due to its relation to the so - called  _ secret number problem _ '' , i.e. , the problem of identifying numbers in financial transactions . from a practical point we show that the natural laws of thermodynamics limit the number of degrees of freedom of a system to those of a single species .<n> this is a consequence of the fact that a system is thermodynamically stable if and only if its degree of freedom is a single variable . <n> we consider the thermodynamics of systems composed of a finite number of particles . in the first part of the paper , we consider a system composed of two species , one of which is a molecule and the other is an atom . for the case of a molecule ,<n> we prove that the number , @xmath0 , of molecules in the system is bounded from above by the number in the atom - molecule potential . to obtain this bound<n> , the system must satisfy the following two conditions : ( i ) the molecule must be in a state of thermodynamical equilibrium , and ( ii ) it must have a non - zero probability of being trapped in a potential well . this is a version of the following question : under what conditions are there restrictions on the ability of a governmental body to act in the best interest of the society it purports to represent ?<n> this question is answered in the affirmative for the following cases : 1 . <n> a government body has the right to impose restrictions on its ability to serve the community in a manner that is consistent with its mission , subject to the following conditions : ( 1 ) any member of the government body can arbitrarily arbitrarily arbitrarily impose restrictions ; ( 2 ) there is no conflict of interest between the mission and the operations of the body ; and ( 3 ) no conflict is caused by the fact that the body has a nonuniform distribution of powers among its members .",
      "metrics": {
        "rougeL": 0.14880201765447668,
        "bertscore_f1": 0.7797222137451172,
        "latency": 4.103772401809692
      },
      "selection_reason": "worst_bertscore"
    }
  ]
}